var documenterSearchIndex = {"docs":
[{"location":"psrdatabase/time_series/#Time-Series","page":"Time Series","title":"Time Series","text":"It is possible to store time series data in your database. Time series in PSRDatabase are very flexible. You can have missing values, and you can have sparse data. \n\nThere is a specific table format that must be followed. Consider the following example:\n\nCREATE TABLE Resource (\n    id INTEGER PRIMARY KEY AUTOINCREMENT,\n    label TEXT UNIQUE NOT NULL\n) STRICT;\n\nCREATE TABLE Resource_time_series_group1 (\n    id INTEGER, \n    date_time TEXT NOT NULL,\n    some_vector1 REAL,\n    some_vector2 REAL,\n    FOREIGN KEY(id) REFERENCES Resource(id) ON DELETE CASCADE ON UPDATE CASCADE,\n    PRIMARY KEY (id, date_time)\n) STRICT; \n\nIt is mandatory for a time series to be indexed by a date_time column with the following format: YYYY-MM-DD HH:MM:SS. You can use the Dates.jl package for handling this format.\n\nusing Dates\ndate = DateTime(2024, 3, 1) # 2024-03-01T00:00:00 (March 1st, 2024)\n\nNotice that in this example, there are two value columns some_vector1 and some_vector2. You can have as many value columns as you want. You can also separate the time series data into different tables, by creating a table Resource_time_series_group2 for example.\n\nIt is also possible to add more dimensions to your time series, such as block and scenario.\n\nCREATE TABLE Resource_time_series_group2 (\n    id INTEGER, \n    date_time TEXT NOT NULL,\n    block INTEGER NOT NULL,\n    some_vector3 REAL,\n    some_vector4 REAL,\n    FOREIGN KEY(id) REFERENCES Resource(id) ON DELETE CASCADE ON UPDATE CASCADE,\n    PRIMARY KEY (id, date_time, block)\n) STRICT; ","category":"section"},{"location":"psrdatabase/time_series/#Rules","page":"Time Series","title":"Rules","text":"Time series in PSRDatabase are very flexible. You can have missing values, and you can have sparse data. \n\nIf you are querying for a time series row entry that has a missing value, it first checks if there is a data with a date_time earlier than the queried date_time. If there is, it returns the value of the previous data. If there is no data earlier than the queried date_time, it returns a specified value according to the type of data you are querying.\n\nFor Float64, it returns NaN.\nFor Int64, it returns typemin(Int).\nFor String, it returns \"\" (empty String).\nFor DateTime, it returns typemin(DateTime).\n\nFor example, if you have the following data:\n\nDate some_vector1(Float64) some_vector2(Float64)\n2020 1.0 missing\n2021 missing 1.0\n2022 3.0 missing\n\nIf you query for some_vector1 at 2020, it returns 1.0. \nIf you query for some_vector2 at 2020, it returns NaN. \nIf you query for some_vector1 at 2021, it returns 1.0. \nIf you query for some_vector2 at 2021, it returns 1.0. \nIf you query for some_vector1 at 2022, it returns 3.0. \nIf you query for some_vector2 at 2022, it returns 1.0.","category":"section"},{"location":"psrdatabase/time_series/#Inserting-data","page":"Time Series","title":"Inserting data","text":"When creating a new element that has a time series, you can pass this information via a DataFrame. Consider the collection Resource with the two time series tables Resource_time_series_group1 and Resource_time_series_group2.\n\nusing DataFrames\nusing Dates\nusing PSRDatabase\nPSRDatabase = PSRDatabase.PSRDatabase\n\ndb = PSRDatabase.create_empty_db_from_schema(db_path, path_schema; force = true)\n\nPSRDatabase.create_element!(db, \"Configuration\"; label = \"Toy Case\", value1 = 1.0)\n\ndf_group1 = DataFrame(;\n        date_time = [DateTime(2000), DateTime(2001), DateTime(2002)],\n        some_vector1 = [missing, 1.0, 2.0],\n        some_vector2 = [1.0, missing, 5.0],\n    )\n\ndf_group2 = DataFrame(;\n            date_time = [\n                DateTime(2000),\n                DateTime(2000),\n                DateTime(2000),\n                DateTime(2000),\n                DateTime(2001),\n                DateTime(2001),\n                DateTime(2001),\n                DateTime(2009),\n            ],\n            block = [1, 1, 1, 1, 2, 2, 2, 2],\n            some_vector3 = [1.0, 2.0, 3.0, 4.0, 1, 2, 3, 4],\n            some_vector4 = [1.0, 2.0, 3.0, 4.0, 1, 2, 3, 4],\n        )\n\n\nPSRDatabase.create_element!(\n    db,\n    \"Resource\";\n    label = \"Resource 1\",\n    group1 = df_group1,\n    group2 = df_group2,\n)\n\nIt is also possible to insert a single row of a time series. This is useful when you want to insert a specific dimension entry. This way of inserting time series is less efficient than inserting a whole DataFrame.\n\nusing DataFrames\nusing Dates\nusing PSRDatabase\nPSRDatabase = PSRDatabase.PSRDatabase\n\ndb = PSRDatabase.create_empty_db_from_schema(db_path, path_schema; force = true)\n\nPSRDatabase.create_element!(db, \"Configuration\"; label = \"Toy Case\", value1 = 1.0)\n\nPSRDatabase.create_element!(\n    db,\n    \"Resource\";\n    label = \"Resource 1\"\n)\n\nPSRDatabase.add_time_series_row!(\n    db,\n    \"Resource\",\n    \"some_vector1\",\n    \"Resource 1\",\n    10.0; # new value\n    date_time = DateTime(2000)\n)\n\nPSRDatabase.add_time_series_row!(\n    db,\n    \"Resource\",\n    \"some_vector1\",\n    \"Resource 1\",\n    11.0; # new value\n    date_time = DateTime(2001)\n)","category":"section"},{"location":"psrdatabase/time_series/#Reading-data","page":"Time Series","title":"Reading data","text":"You can read the information from the time series in two different ways.","category":"section"},{"location":"psrdatabase/time_series/#Reading-as-a-table","page":"Time Series","title":"Reading as a table","text":"First, you can read the whole time series table for a given value, as a DataFrame.\n\ndf = PSRDatabase.read_time_series_table(\n    db,\n    \"Resource\",\n    \"some_vector1\",\n    \"Resource 1\",\n)","category":"section"},{"location":"psrdatabase/time_series/#Reading-a-single-row","page":"Time Series","title":"Reading a single row","text":"It is also possible to read a single row of the time series in the form of an array. This is useful when you want to query a specific dimension entry. For this function, there are performance improvements when reading the data via caching the previous and next non-missing values. \n\nvalues = PSRDatabase.read_time_series_row(\n    db,\n    \"Resource\",\n    \"some_vector1\",\n    Float64;\n    date_time = DateTime(2020)\n)\n\nWhen querying a row, all values should non-missing. However, if there is a missing value, the function will return the previous non-missing value. And if even the previous value is missing, it will return a specified value according to the type of data you are querying.\n\nFor Float64, it returns NaN.\nFor Int64, it returns typemin(Int).\nFor String, it returns \"\" (empty String).\nFor DateTime, it returns typemin(DateTime).\n\nFor example, if you have the following data for the time series some_vector1:\n\nDate Resource 1 Resource 2\n2020 1.0 missing\n2021 missing 1.0\n2022 3.0 missing\n\nIf you query at 2020, it returns [1.0, NaN]. \nIf you query at 2021, it returns [1.0, 1.0]. \nIf you query at 2022, it returns [3.0, 1.0]. ","category":"section"},{"location":"psrdatabase/time_series/#Updating-data","page":"Time Series","title":"Updating data","text":"When updating one of the entries of a time series for a given element and attribute, you need to specify the exact dimension values of the row you want to update. \n\nFor example, consider a time series that has block and data_time dimensions.\n\nPSRDatabase.update_time_series_row!(\n    db,\n    \"Resource\",\n    \"some_vector3\",\n    \"Resource 1\",\n    10.0; # new value\n    date_time = DateTime(2000),\n    block = 1\n)","category":"section"},{"location":"psrdatabase/time_series/#Deleting-data","page":"Time Series","title":"Deleting data","text":"You can delete the whole time series of an element for a given time series group. Consider the following table:\n\nCREATE TABLE Resource_time_series_group1 (\n    id INTEGER, \n    date_time TEXT NOT NULL,\n    some_vector1 REAL,\n    some_vector2 REAL,\n    FOREIGN KEY(id) REFERENCES Resource(id) ON DELETE CASCADE ON UPDATE CASCADE,\n    PRIMARY KEY (id, date_time)\n) STRICT; \n\nThis table represents a \"group\" that stores two time series some_vector1 and some_vector2. You can delete all the data from this group by calling the following function:\n\nPSRDatabase.delete_time_series!(\n    db,\n    \"Resource\",\n    \"group1\",\n    \"Resource 1\",\n)\n\nWhen trying to read a time series that has been deleted, the function will return an empty DataFrame.","category":"section"},{"location":"api_reference/#PSRDatabase-API","page":"API Reference","title":"PSRDatabase API","text":"","category":"section"},{"location":"api_reference/#Database-Functions","page":"API Reference","title":"Database Functions","text":"","category":"section"},{"location":"api_reference/#Migration-Functions","page":"API Reference","title":"Migration Functions","text":"","category":"section"},{"location":"api_reference/#Data-Structures","page":"API Reference","title":"Data Structures","text":"","category":"section"},{"location":"api_reference/#Read-Functions","page":"API Reference","title":"Read Functions","text":"","category":"section"},{"location":"api_reference/#Create-Functions","page":"API Reference","title":"Create Functions","text":"","category":"section"},{"location":"api_reference/#Update-Functions","page":"API Reference","title":"Update Functions","text":"","category":"section"},{"location":"api_reference/#Delete-Functions","page":"API Reference","title":"Delete Functions","text":"","category":"section"},{"location":"api_reference/#Utility-Functions","page":"API Reference","title":"Utility Functions","text":"","category":"section"},{"location":"api_reference/#Validation-Functions","page":"API Reference","title":"Validation Functions","text":"","category":"section"},{"location":"api_reference/#Automatic-Docstring-Generation","page":"API Reference","title":"Automatic Docstring Generation","text":"","category":"section"},{"location":"api_reference/#Comparing-Databases","page":"API Reference","title":"Comparing Databases","text":"","category":"section"},{"location":"api_reference/#PSRDatabase.close!-Tuple{PSRDatabase.DatabaseSQLite}","page":"API Reference","title":"PSRDatabase.close!","text":"close!(db::DatabaseSQLite)\n\nClose the database connection.\n\nThis function closes the SQLite database connection and releases any associated resources. Always call this function when you're done working with a database to ensure proper cleanup.\n\nArguments\n\ndb::DatabaseSQLite: The database connection to close\n\nReturns\n\nNothing\n\nExamples\n\n# Open a database\ndb = PSRDatabase.load_db(\"my_database.sqlite\")\n\n# Work with the database\n# ... perform operations ...\n\n# Close the database when done\nPSRDatabase.close!(db)\n\nNotes\n\nAfter closing, the database connection cannot be used for further operations. You'll need to call load_db again if you want to work with the database.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PSRDatabase.create_migration-Tuple{String, Integer}","page":"API Reference","title":"PSRDatabase.create_migration","text":"create_migration(path_migrations_directory::String, version::Integer)\n\nCreates a new migration in the migrations folder with the current date, the correct version and the name given in this function\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PSRDatabase.generate_current_schema_file-Tuple{SQLite.DB, String}","page":"API Reference","title":"PSRDatabase.generate_current_schema_file","text":"generate_current_schema_file(db::SQLite.DB, file::String)\n\nGenerates a .sql file based in sqlite_master that indicates the statements to create a new db from scratch.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PSRDatabase.test_migrations-Tuple{String}","page":"API Reference","title":"PSRDatabase.test_migrations","text":"test_migrations(path_migrations_directory::String)\n\nFunction to put in the test suite of the module to verify that the migrations are behaving correctly.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PSRDatabase.Collection","page":"API Reference","title":"PSRDatabase.Collection","text":"Collection\n\nThis struct stores the definition of a collection\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#PSRDatabase.Attribute","page":"API Reference","title":"PSRDatabase.Attribute","text":"Attribute\n\nAbstract type for attributes, the building blocks of collections.\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#PSRDatabase.READ_METHODS_BY_CLASS_OF_ATTRIBUTE","page":"API Reference","title":"PSRDatabase.READ_METHODS_BY_CLASS_OF_ATTRIBUTE","text":"const READ_METHODS_BY_CLASS_OF_ATTRIBUTE\n\nA dictionary mapping attribute classes to their corresponding read method names in PSRDatabase.\n\n\n\n\n\n","category":"constant"},{"location":"api_reference/#PSRDatabase._PSRDatabase_null_value-Tuple{Type{Float64}}","page":"API Reference","title":"PSRDatabase._PSRDatabase_null_value","text":"_PSRDatabase_null_value(::Type{Float64})\n_PSRDatabase_null_value(::Type{Int64})\n_PSRDatabase_null_value(::Type{String})\n_PSRDatabase_null_value(::Type{DateTime})\n\nGet the null/missing value representation for a specific type in PSRDatabase.\n\nArguments\n\nType parameter: The data type to get the null value for\n\nReturns\n\nFor Float64: NaN\nFor Int64: typemin(Int64)\nFor String: \"\"\nFor DateTime: typemin(DateTime)\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PSRDatabase._get_id-Tuple{PSRDatabase.DatabaseSQLite, String, String}","page":"API Reference","title":"PSRDatabase._get_id","text":"_get_id(db::DatabaseSQLite, collection_id::String, label::String)::Integer\n\nInternal function to retrieve the numeric ID for an element in a collection based on its label.\n\nArguments\n\ndb::DatabaseSQLite: The database connection\ncollection_id::String: The identifier of the collection\nlabel::String: The label of the element to find\n\nReturns\n\nInteger: The numeric ID of the element\n\nThrows\n\nError if the label does not exist in the collection\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PSRDatabase._get_scalar_relation_map-Tuple{PSRDatabase.DatabaseSQLite, String, String, String}","page":"API Reference","title":"PSRDatabase._get_scalar_relation_map","text":"_get_scalar_relation_map(db::DatabaseSQLite, collection_from::String, collection_to::String, relation_type::String)\n\nInternal function to retrieve the scalar relation mapping as a vector of indices.\n\nArguments\n\ndb::DatabaseSQLite: The database connection\ncollection_from::String: The identifier of the source collection\ncollection_to::String: The identifier of the target collection\nrelation_type::String: The type of relation\n\nReturns\n\nVector{Int}: A vector of indices mapping each element in collection_from to elements in collection_to\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PSRDatabase._get_set_relation_map-Tuple{PSRDatabase.DatabaseSQLite, String, String, String}","page":"API Reference","title":"PSRDatabase._get_set_relation_map","text":"_get_set_relation_map(db::DatabaseSQLite, collection_from::String, collection_to::String, relation_type::String)\n\nInternal function to retrieve the set relation mapping as a vector of index vectors.\n\nArguments\n\ndb::DatabaseSQLite: The database connection\ncollection_from::String: The identifier of the source collection\ncollection_to::String: The identifier of the target collection\nrelation_type::String: The type of relation\n\nReturns\n\n- `Vector{Vector{Int}}`: A vector of vectors of indices mapping each element in `collection_from` to elements in `collection_to`\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PSRDatabase._get_vector_relation_map-Tuple{PSRDatabase.DatabaseSQLite, String, String, String}","page":"API Reference","title":"PSRDatabase._get_vector_relation_map","text":"_get_vector_relation_map(db::DatabaseSQLite, collection_from::String, collection_to::String, relation_type::String)\n\nInternal function to retrieve the vector relation mapping as a vector of index vectors.\n\nArguments\n\ndb::DatabaseSQLite: The database connection\ncollection_from::String: The identifier of the source collection\ncollection_to::String: The identifier of the target collection\nrelation_type::String: The type of relation\n\nReturns\n\nVector{Vector{Int}}: A vector of vectors of indices mapping each element in collection_from to elements in collection_to\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PSRDatabase._is_null_in_db-Tuple{Float64}","page":"API Reference","title":"PSRDatabase._is_null_in_db","text":"_is_null_in_db(value::Float64)\n_is_null_in_db(value::Int64)\n_is_null_in_db(value::String)\n_is_null_in_db(value::DateTime)\n\nCheck if a value represents a null/missing value in PSRDatabase.\n\nArguments\n\nvalue: The value to check\n\nReturns\n\nBool: true if the value is null, false otherwise\n\nDetails\n\nFor Float64: checks if isnan(value)\nFor Int64: checks if value == typemin(Int64)\nFor String: checks if isempty(value)\nFor DateTime: checks if value == typemin(DateTime)\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PSRDatabase._query_set-Tuple{PSRDatabase.DatabaseSQLite, PSRDatabase.SetParameter, Integer}","page":"API Reference","title":"PSRDatabase._query_set","text":"_query_set(db::DatabaseSQLite, attribute::SetParameter, id::Integer; default::Union{Nothing, Any} = nothing)\n\nInternal function to query set parameter values for a specific element.\n\nArguments\n\ndb::DatabaseSQLite: The database connection\nattribute::SetParameter: The set parameter attribute\nid::Integer: The numeric ID of the element\ndefault::Union{Nothing, Any}: Optional default value for missing data\n\nReturns\n\n- `Vector`: The vector of set parameter values, ordered by rowid\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PSRDatabase._query_vector-Tuple{PSRDatabase.DatabaseSQLite, PSRDatabase.VectorParameter, Integer}","page":"API Reference","title":"PSRDatabase._query_vector","text":"_query_vector(db::DatabaseSQLite, attribute::VectorParameter, id::Integer; default::Union{Nothing, Any} = nothing)\n\nInternal function to query vector parameter values for a specific element.\n\nArguments\n\ndb::DatabaseSQLite: The database connection\nattribute::VectorParameter: The vector parameter attribute\nid::Integer: The numeric ID of the element\ndefault::Union{Nothing, Any}: Optional default value for missing data\n\nReturns\n\nVector: The vector of parameter values, ordered by vector_index\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PSRDatabase._read_time_series_table-Tuple{PSRDatabase.DatabaseSQLite, PSRDatabase.Attribute, Integer}","page":"API Reference","title":"PSRDatabase._read_time_series_table","text":"_read_time_series_table(db::DatabaseSQLite, attribute::Attribute, id::Integer)\n\nInternal function to read the complete time series table for a specific element.\n\nArguments\n\ndb::DatabaseSQLite: The database connection\nattribute::Attribute: The time series attribute\nid::Integer: The numeric ID of the element\n\nReturns\n\nDataFrame: A DataFrame containing all time series data for the element\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PSRDatabase._treat_query_result-Tuple{Vector{<:Union{Missing, String}}, PSRDatabase.Attribute, Any}","page":"API Reference","title":"PSRDatabase._treat_query_result","text":"_treat_query_result(query_results::Vector{<:Union{Missing, String}}, attribute::Attribute, default::Union{Nothing, Any})\n\nInternal function to process string query results, replacing missing values with appropriate defaults. Handles both String and DateTime types (DateTime values are stored as strings in the database).\n\nArguments\n\nquery_results::Vector{<:Union{Missing, String}}: The query results that may contain missing values\nattribute::Attribute: The attribute being queried\ndefault::Union{Nothing, Any}: The default value to use for missing data\n\nReturns\n\nA vector with missing values replaced by the specified default, with DateTime conversion if applicable\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PSRDatabase._treat_query_result-Tuple{Vector{Missing}, PSRDatabase.Attribute, Any}","page":"API Reference","title":"PSRDatabase._treat_query_result","text":"_treat_query_result(query_results::Vector{Missing}, attribute::Attribute, default::Union{Nothing, Any})\n\nInternal function to process query results that are all missing values, replacing them with appropriate defaults.\n\nArguments\n\nquery_results::Vector{Missing}: The query results containing only missing values\nattribute::Attribute: The attribute being queried\ndefault::Union{Nothing, Any}: The default value to use for missing data\n\nReturns\n\nA vector filled with the appropriate default values\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PSRDatabase._treat_query_result-Union{Tuple{T}, Tuple{Array{Union{Missing, T}, 1}, PSRDatabase.Attribute, Any}} where T<:Union{Float64, Int64}","page":"API Reference","title":"PSRDatabase._treat_query_result","text":"_treat_query_result(query_results::Vector{Union{Missing, T}}, attribute::Attribute, default::Union{Nothing, Any}) where {T <: Union{Int64, Float64}}\n\nInternal function to process numeric query results, replacing missing values with appropriate defaults.\n\nArguments\n\nquery_results::Vector{Union{Missing, T}}: The query results that may contain missing values\nattribute::Attribute: The attribute being queried\ndefault::Union{Nothing, Any}: The default value to use for missing data\n\nReturns\n\nA vector with missing values replaced by the specified default\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PSRDatabase._treat_query_result-Union{Tuple{T}, Tuple{Vector{T}, PSRDatabase.Attribute, Any}} where T<:Union{Float64, Int64}","page":"API Reference","title":"PSRDatabase._treat_query_result","text":"_treat_query_result(results::Vector{T}, ::Attribute, ::Union{Nothing, Any}) where {T <: Union{Int64, Float64}}\n\nInternal function to process numeric query results that contain no missing values. Returns the results unchanged.\n\nArguments\n\nresults::Vector{T}: The query results with no missing values\n::Attribute: The attribute being queried (unused)\n::Union{Nothing, Any}: The default value (unused)\n\nReturns\n\nThe original results vector unchanged\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PSRDatabase.number_of_elements-Tuple{PSRDatabase.DatabaseSQLite, String}","page":"API Reference","title":"PSRDatabase.number_of_elements","text":"number_of_elements(db::DatabaseSQLite, collection_id::String)::Int\n\nReturn the total number of elements in the specified collection.\n\nArguments\n\ndb::DatabaseSQLite: The database connection\ncollection_id::String: The identifier of the collection to count elements from\n\nReturns\n\nInt: The number of elements in the collection\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PSRDatabase.read_scalar_parameter-Tuple{PSRDatabase.DatabaseSQLite, String, String, Integer}","page":"API Reference","title":"PSRDatabase.read_scalar_parameter","text":"read_scalar_parameter(db::DatabaseSQLite, collection_id::String, attribute_id::String, id::Integer; default::Union{Nothing, Any} = nothing)\n\nRead the value of a scalar parameter attribute for a specific element identified by numeric ID.\n\nArguments\n\ndb::DatabaseSQLite: The database connection\ncollection_id::String: The identifier of the collection\nattribute_id::String: The identifier of the scalar parameter attribute to read\nid::Integer: The numeric ID of the element to read from\ndefault::Union{Nothing, Any}: Optional default value to use for missing data. If nothing, uses type-specific null values\n\nReturns\n\nThe scalar parameter value for the specified element. Type matches the attribute type (Float64, Int64, String, or DateTime)\n\nExample\n\ncapacity = PSRDatabase.read_scalar_parameter(db, \"Plant\", \"capacity\", 1)  # 2.02\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PSRDatabase.read_scalar_parameter-Tuple{PSRDatabase.DatabaseSQLite, String, String, String}","page":"API Reference","title":"PSRDatabase.read_scalar_parameter","text":"read_scalar_parameter(db::DatabaseSQLite, collection_id::String, attribute_id::String, label::String; default::Union{Nothing, Any} = nothing)\n\nRead the value of a scalar parameter attribute for a specific element identified by label.\n\nArguments\n\ndb::DatabaseSQLite: The database connection\ncollection_id::String: The identifier of the collection\nattribute_id::String: The identifier of the scalar parameter attribute to read\nlabel::String: The label of the element to read from\ndefault::Union{Nothing, Any}: Optional default value to use for missing data. If nothing, uses type-specific null values\n\nReturns\n\nThe scalar parameter value for the specified element. Type matches the attribute type (Float64, Int64, String, or DateTime)\n\nExamples\n\n# Read a string label\nname = PSRDatabase.read_scalar_parameter(db, \"Resource\", \"label\", \"Resource 1\")  # \"Resource 1\"\n\n# Read a numeric value\ncapacity = PSRDatabase.read_scalar_parameter(db, \"Plant\", \"capacity\", \"Plant 3\")  # 54.0\n\nThrows\n\nDatabaseException if the label does not exist in the collection\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PSRDatabase.read_scalar_parameters-Tuple{PSRDatabase.DatabaseSQLite, String, String}","page":"API Reference","title":"PSRDatabase.read_scalar_parameters","text":"read_scalar_parameters(db::DatabaseSQLite, collection_id::String, attribute_id::String; default::Union{Nothing, Any} = nothing)\n\nRead all values of a scalar parameter attribute for all elements in a collection.\n\nArguments\n\ndb::DatabaseSQLite: The database connection\ncollection_id::String: The identifier of the collection\nattribute_id::String: The identifier of the scalar parameter attribute to read\ndefault::Union{Nothing, Any}: Optional default value to use for missing data. If nothing, uses type-specific null values (NaN for Float64, typemin(Int64) for Int64, \"\" for String, typemin(DateTime) for DateTime)\n\nReturns\n\nVector: A vector containing the scalar parameter values for all elements, ordered by ID. The element type matches the attribute type (Float64, Int64, String, or DateTime)\n\nExamples\n\n# Read labels (returns Vector{String})\nlabels = PSRDatabase.read_scalar_parameters(db, \"Plant\", \"label\")  # [\"Plant 1\", \"Plant 2\", \"Plant 3\"]\n\n# Read numeric values (returns Vector{Float64})\ncapacities = PSRDatabase.read_scalar_parameters(db, \"Plant\", \"capacity\")  # [2.02, 53.0, 54.0]\n\n# Read dates (returns Vector{DateTime})\ndates = PSRDatabase.read_scalar_parameters(db, \"Configuration\", \"date_initial\")  # [DateTime(2020, 1, 1)]\n\n# With default value for missing data\nvalues = PSRDatabase.read_scalar_parameters(db, \"Cost\", \"value_without_default\"; default = 2.0)  # [2.0, 2.0]\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PSRDatabase.read_scalar_relation-Tuple{PSRDatabase.DatabaseSQLite, Vararg{String, 4}}","page":"API Reference","title":"PSRDatabase.read_scalar_relation","text":"read_scalar_relation(db::DatabaseSQLite, collection_from::String, collection_to::String, relation_type::String, collection_from_label::String)\n\nRead the scalar relation mapping for a specific element from one collection to another.\n\nArguments\n\ndb::DatabaseSQLite: The database connection\ncollection_from::String: The identifier of the source collection\ncollection_to::String: The identifier of the target collection\nrelation_type::String: The type of relation (e.g., \"id\", \"group\", \"turbine_to\")\ncollection_from_label::String: The label of the element in the source collection\n\nReturns\n\nString: The label from collection_to that the specified element relates to. Empty string (\"\") indicates a null relation (no connection).\n\nExamples\n\n# Get which resource \"Plant 1\" is connected to\nresource = PSRDatabase.read_scalar_relation(db, \"Plant\", \"Resource\", \"id\", \"Plant 1\")  # \"Resource 1\"\n\n# Get which plant \"Plant 3\" connects to via turbine\nturbine = PSRDatabase.read_scalar_relation(db, \"Plant\", \"Plant\", \"turbine_to\", \"Plant 3\")  # \"Plant 2\"\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PSRDatabase.read_scalar_relations-Tuple{PSRDatabase.DatabaseSQLite, String, String, String}","page":"API Reference","title":"PSRDatabase.read_scalar_relations","text":"read_scalar_relations(db::DatabaseSQLite, collection_from::String, collection_to::String, relation_type::String)\n\nRead all scalar relation mappings from one collection to another.\n\nArguments\n\ndb::DatabaseSQLite: The database connection\ncollection_from::String: The identifier of the source collection\ncollection_to::String: The identifier of the target collection\nrelation_type::String: The type of relation (e.g., \"id\", \"group\", \"turbine_to\")\n\nReturns\n\nVector{String}: A vector of labels from collection_to representing the relation for each element in collection_from, ordered by ID. Empty strings (\"\") indicate null relations (no connection).\n\nExamples\n\n# Get which resource each plant is connected to\nresources = PSRDatabase.read_scalar_relations(db, \"Plant\", \"Resource\", \"id\")\n# [\"Resource 1\", \"\", \"\"]  # Plant 1 → Resource 1, Plant 2 and 3 → no resource\n\n# Get turbine connections between plants\nturbines = PSRDatabase.read_scalar_relations(db, \"Plant\", \"Plant\", \"turbine_to\")\n# [\"\", \"\", \"Plant 2\"]  # Only Plant 3 connects to Plant 2\n\nThrows\n\nDatabaseException if the relation is not a scalar relation (e.g., trying to read a vector relation)\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PSRDatabase.read_set_parameter-Tuple{PSRDatabase.DatabaseSQLite, String, String, String}","page":"API Reference","title":"PSRDatabase.read_set_parameter","text":"read_set_parameter(db::DatabaseSQLite, collection_id::String, attribute_id::String, label::String; default::Union{Nothing, Any} = nothing)\n\nRead the values of a set parameter attribute for a specific element identified by label.\n\nArguments\n\ndb::DatabaseSQLite: The database connection\ncollection_id::String: The identifier of the collection\nattribute_id::String: The identifier of the set parameter attribute to read\nlabel::String: The label of the element to read from\ndefault::Union{Nothing, Any}: Optional default value to use for missing data. If nothing, uses type-specific null values\n\nReturns\n\n- `Vector`: A vector containing the parameter values for the specified element. Type matches the attribute type (Float64, Int64, String, or DateTime). Returns an empty vector if no data exists.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PSRDatabase.read_set_parameters-Tuple{PSRDatabase.DatabaseSQLite, String, String}","page":"API Reference","title":"PSRDatabase.read_set_parameters","text":"read_set_parameters(db::DatabaseSQLite, collection_id::String, attribute_id::String; default::Union{Nothing, Any} = nothing)\n\nRead all values of a set parameter attribute for all elements in a collection.\n\nArguments\n\ndb::DatabaseSQLite: The database connection\ncollection_id::String: The identifier of the collection\nattribute_id::String: The identifier of the set parameter attribute to read\ndefault::Union{Nothing, Any}: Optional default value to use for missing data. If nothing, uses type-specific null values\n\nReturns\n\n- `Vector{Vector}`: A vector of vectors, where each inner vector contains the parameter values for one element. Inner vector type matches the attribute type (Float64, Int64, String, or DateTime). Empty vectors are returned for elements with no data.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PSRDatabase.read_set_relation-Tuple{PSRDatabase.DatabaseSQLite, Vararg{String, 4}}","page":"API Reference","title":"PSRDatabase.read_set_relation","text":"read_set_relation(db::DatabaseSQLite, collection_from::String, collection_to::String, collection_from_label::String, relation_type::String)\n\nRead the set relation mapping for a specific element from one collection to another.\n\nArguments\n\ndb::DatabaseSQLite: The database connection\ncollection_from::String: The identifier of the source collection\ncollection_to::String: The identifier of the target collection\ncollection_from_label::String: The label of the element in the source collection\nrelation_type::String: The type of relation \n\nReturns\n\n- `Vector{String}`: A vector of labels from `collection_to` that the specified element relates to. Returns an empty vector if no relations exist. Empty strings within the vector indicate null relations.\n\nExamples\n\n# Get which costs \"Plant 1\" is associated with\ncosts = PSRDatabase.read_set_relation(db, \"Plant\", \"Cost\", \"Plant 1\", \"id\")  # [\"Cost 2\"]\n# Get multiple related elements\ncosts = PSRDatabase.read_set_relation(db, \"Plant\", \"Cost\", \"Plant 2\", \"id\")  # [\"Cost 1\", \"Cost 2\"]\n# Element with no relations\ncosts = PSRDatabase.read_set_relation(db, \"Plant\", \"Cost\", \"Plant 3\", \"id\")  # String[]\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PSRDatabase.read_set_relations-Tuple{PSRDatabase.DatabaseSQLite, String, String, String}","page":"API Reference","title":"PSRDatabase.read_set_relations","text":"read_set_relation(db::DatabaseSQLite, collection_from::String, collection_to::String, collection_from_label::String, relation_type::String)\n\nRead the set relation mapping for a specific element from one collection to another.\n\nArguments\n\ndb::DatabaseSQLite: The database connection\ncollection_from::String: The identifier of the source collection\ncollection_to::String: The identifier of the target collection\ncollection_from_label::String: The label of the element in the source collection\nrelation_type::String: The type of relation \n\nReturns\n\nVector{String}: A vector of labels from collection_to that the specified element relates to. Returns an empty vector if no relations exist. Empty strings within the vector indicate null relations.\n\nExamples\n\n# Get which costs \"Plant 1\" is associated with\ncosts = PSRDatabase.read_set_relations(db, \"Plant\", \"Cost\", \"Plant 1\", \"id\")  # [\"Cost 2\"]\n\n# Get multiple related elements\ncosts = PSRDatabase.read_set_relations(db, \"Plant\", \"Cost\", \"Plant 2\", \"id\")  # [\"Cost 1\", \"Cost 2\"]\n\n# Element with no relations\ncosts = PSRDatabase.read_set_relations(db, \"Plant\", \"Cost\", \"Plant 3\", \"id\")  # String[]\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PSRDatabase.read_time_series_file-Tuple{PSRDatabase.DatabaseSQLite, String, String}","page":"API Reference","title":"PSRDatabase.read_time_series_file","text":"read_time_series_file(db::DatabaseSQLite, collection_id::String, attribute_id::String)::String\n\nRead the file path stored in a time series file attribute.\n\nTime series file attributes store references to external files containing time series data. This function retrieves the file path string.\n\nArguments\n\ndb::DatabaseSQLite: The database connection\ncollection_id::String: The identifier of the collection\nattribute_id::String: The identifier of the time series file attribute\n\nReturns\n\nString: The file path stored in the attribute, or an empty string (\"\") if not set\n\nExamples\n\n# Read time series file paths\nwind_file = PSRDatabase.read_time_series_file(db, \"Plant\", \"wind_speed\")  # \"some_file.txt\"\ndirection_file = PSRDatabase.read_time_series_file(db, \"Plant\", \"wind_direction\")  # \"some_file2\"\n\n# After updating\nPSRDatabase.set_time_series_file!(db, \"Plant\"; wind_speed = \"some_file3.txt\")\nwind_file = PSRDatabase.read_time_series_file(db, \"Plant\", \"wind_speed\")  # \"some_file3.txt\"\n\nThrows\n\nDatabaseException if the attribute is not a time series file attribute\nDatabaseException if the table has more than one row (should only have one row for time series file attributes)\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PSRDatabase.read_time_series_row-Tuple{Any, String, String}","page":"API Reference","title":"PSRDatabase.read_time_series_row","text":"read_time_series_row(db::DatabaseSQLite, collection_id::String, attribute_id::String; date_time::DateTime)\n\nRead a row of time series data for all elements in a collection at a specific date/time.\n\nThis function is optimized for read-only databases and uses caching for efficient access to time series data.\n\nArguments\n\ndb::DatabaseSQLite: The database connection (must be read-only)\ncollection_id::String: The identifier of the collection\nattribute_id::String: The identifier of the time series attribute\ndate_time::DateTime: The date/time to query data for\n\nReturns\n\nVector: A vector containing the time series values for all elements at the specified date/time\n\nNote\n\nThis function only works with read-only databases and will throw an error if called on a writable database.\n\nExample\n\ngeneration = PSRDatabase.read_time_series_row(db, \"Thermal\", \"generation\"; date_time = DateTime(2025, 1, 1))\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PSRDatabase.read_time_series_table-Tuple{PSRDatabase.DatabaseSQLite, String, String, String}","page":"API Reference","title":"PSRDatabase.read_time_series_table","text":"read_time_series_table(db::DatabaseSQLite, collection_id::String, attribute_id::String, label::String)\n\nRead the complete time series table for a specific element identified by label.\n\nArguments\n\ndb::DatabaseSQLite: The database connection\ncollection_id::String: The identifier of the collection\nattribute_id::String: The identifier of the time series attribute\nlabel::String: The label of the element to read data for\n\nReturns\n\nDataFrame: A DataFrame containing all time series data (dimensions and values) for the specified element\n\nExample\n\ngeneration_table = PSRDatabase.read_time_series_table(db, \"Thermal\", \"generation\", \"Plant1\")\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PSRDatabase.read_vector_parameter-Tuple{PSRDatabase.DatabaseSQLite, String, String, String}","page":"API Reference","title":"PSRDatabase.read_vector_parameter","text":"read_vector_parameter(db::DatabaseSQLite, collection_id::String, attribute_id::String, label::String; default::Union{Nothing, Any} = nothing)\n\nRead the values of a vector parameter attribute for a specific element identified by label.\n\nArguments\n\ndb::DatabaseSQLite: The database connection\ncollection_id::String: The identifier of the collection\nattribute_id::String: The identifier of the vector parameter attribute to read\nlabel::String: The label of the element to read from\ndefault::Union{Nothing, Any}: Optional default value to use for missing data. If nothing, uses type-specific null values\n\nReturns\n\nVector: A vector containing the parameter values for the specified element. Type matches the attribute type (Float64, Int64, String, or DateTime). Returns an empty vector if no data exists.\n\nExamples\n\n# Read vector with data\nfactors = PSRDatabase.read_vector_parameter(db, \"Plant\", \"some_factor\", \"Plant 1\")  # [1.0]\nfactors = PSRDatabase.read_vector_parameter(db, \"Plant\", \"some_factor\", \"Plant 2\")  # [1.0, 2.0]\n\n# Read empty vector\nfactors = PSRDatabase.read_vector_parameter(db, \"Plant\", \"some_factor\", \"Plant 3\")  # Float64[]\n\n# Read date vectors\ndates = PSRDatabase.read_vector_parameter(db, \"Plant\", \"date_some_date\", \"Plant 2\")\n# [DateTime(2020, 1, 1), DateTime(2020, 1, 2)]\n\n# Elements with null dates return typemin(DateTime)\ndates = PSRDatabase.read_vector_parameter(db, \"Plant\", \"date_some_date\", \"Plant 4\")\n# [typemin(DateTime), typemin(DateTime)]\n\nThrows\n\nDatabaseException if the label does not exist in the collection\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PSRDatabase.read_vector_parameters-Tuple{PSRDatabase.DatabaseSQLite, String, String}","page":"API Reference","title":"PSRDatabase.read_vector_parameters","text":"read_vector_parameters(db::DatabaseSQLite, collection_id::String, attribute_id::String; default::Union{Nothing, Any} = nothing)\n\nRead all values of a vector parameter attribute for all elements in a collection.\n\nArguments\n\ndb::DatabaseSQLite: The database connection\ncollection_id::String: The identifier of the collection\nattribute_id::String: The identifier of the vector parameter attribute to read\ndefault::Union{Nothing, Any}: Optional default value to use for missing data. If nothing, uses type-specific null values\n\nReturns\n\nVector{Vector}: A vector of vectors, where each inner vector contains the parameter values for one element. Inner vector type matches the attribute type (Float64, Int64, String, or DateTime). Empty vectors are returned for elements with no data.\n\nExamples\n\n# Read numeric vector parameters\nvalues = PSRDatabase.read_vector_parameters(db, \"Resource\", \"some_value\")\n# [[1, 2, 3.0], [1, 2, 4.0]]\n\n# Read vector parameters with some empty elements\nfactors = PSRDatabase.read_vector_parameters(db, \"Plant\", \"some_factor\")\n# [[1.0], [1.0, 2.0], Float64[], [1.0, 2.0]]\n\n# Read date vectors\ndates = PSRDatabase.read_vector_parameters(db, \"Plant\", \"date_some_date\")\n# [[DateTime(2020, 1, 1)], [DateTime(2020, 1, 1), DateTime(2020, 1, 2)], DateTime[], ...]\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PSRDatabase.read_vector_relation-Tuple{PSRDatabase.DatabaseSQLite, Vararg{String, 4}}","page":"API Reference","title":"PSRDatabase.read_vector_relation","text":"read_vector_relation(db::DatabaseSQLite, collection_from::String, collection_to::String, collection_from_label::String, relation_type::String)\n\nRead the vector relation mapping for a specific element from one collection to another.\n\nArguments\n\ndb::DatabaseSQLite: The database connection\ncollection_from::String: The identifier of the source collection\ncollection_to::String: The identifier of the target collection\ncollection_from_label::String: The label of the element in the source collection\nrelation_type::String: The type of relation \n\nReturns\n\nVector{String}: A vector of labels from collection_to that the specified element relates to. Returns an empty vector if no relations exist. Empty strings within the vector indicate null relations.\n\nExamples\n\n# Get which costs \"Plant 1\" is associated with\ncosts = PSRDatabase.read_vector_relation(db, \"Plant\", \"Cost\", \"Plant 1\", \"id\")  # [\"Cost 2\"]\n\n# Get multiple related elements\ncosts = PSRDatabase.read_vector_relation(db, \"Plant\", \"Cost\", \"Plant 2\", \"id\")  # [\"Cost 1\", \"Cost 2\"]\n\n# Element with no relations\ncosts = PSRDatabase.read_vector_relation(db, \"Plant\", \"Cost\", \"Plant 3\", \"id\")  # String[]\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PSRDatabase.read_vector_relations-Tuple{PSRDatabase.DatabaseSQLite, String, String, String}","page":"API Reference","title":"PSRDatabase.read_vector_relations","text":"read_vector_relations(db::DatabaseSQLite, collection_from::String, collection_to::String, relation_type::String)\n\nRead all vector relation mappings from one collection to another.\n\nArguments\n\ndb::DatabaseSQLite: The database connection\ncollection_from::String: The identifier of the source collection\ncollection_to::String: The identifier of the target collection\nrelation_type::String: The type of relation \n\nReturns\n\nVector{Vector{String}}: A vector of vectors, where each inner vector contains labels from collection_to representing the relations for one element in collection_from, ordered by ID. Empty vectors indicate no relations. Empty strings within vectors indicate null relations.\n\nExamples\n\n# Get which costs each plant is associated with\ncosts = PSRDatabase.read_vector_relations(db, \"Plant\", \"Cost\", \"id\")\n# [[\"Cost 1\"], [\"Cost 1\", \"Cost 2\"], String[]]\n# Plant 1 → Cost 1, Plant 2 → Cost 1 and Cost 2, Plant 3 → no costs\n\n# After updating Plant 1's costs\nPSRDatabase.set_vector_relation!(db, \"Plant\", \"Cost\", \"Plant 1\", [\"Cost 2\"], \"id\")\ncosts = PSRDatabase.read_vector_relations(db, \"Plant\", \"Cost\", \"id\")\n# [[\"Cost 2\"], [\"Cost 1\", \"Cost 2\"], String[]]\n\nThrows\n\nDatabaseException if the relation is not a vector relation (e.g., trying to read a scalar relation)\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PSRDatabase.add_time_series_row!-Tuple{PSRDatabase.DatabaseSQLite, String, String, String, Any}","page":"API Reference","title":"PSRDatabase.add_time_series_row!","text":"add_time_series_row!(db::DatabaseSQLite, collection_id::String, attribute_id::String, label::String, val; dimensions...)\n\nAdd or update a value in a time series attribute for a specific element and dimension combination.\n\nThis function performs an \"upsert\" operation - if a row with the specified dimensions already exists, it updates the value; otherwise, it inserts a new row.\n\nArguments\n\ndb::DatabaseSQLite: The database connection\ncollection_id::String: The identifier of the collection containing the element\nattribute_id::String: The identifier of the time series attribute\nlabel::String: The label of the element to add/update the time series value for\nval: The value to set for the time series at the specified dimensions\ndimensions...: Named arguments specifying the dimension values (e.g., date_time = DateTime(2020, 1, 1), stage = 1)\n\nReturns\n\nnothing\n\nThrows\n\nDatabaseException if the attribute is not a time series\nDatabaseException if the number of dimensions doesn't match the attribute definition\nDatabaseException if dimension names don't match the attribute definition\n\nExamples\n\n# Add time series value with date_time dimension\nPSRDatabase.add_time_series_row!(\n    db,\n    \"Plant\",\n    \"generation\",\n    \"Plant 1\",\n    100.5;\n    date_time = DateTime(2020, 1, 1),\n)\n\n# Add time series value with multiple dimensions\nPSRDatabase.add_time_series_row!(\n    db,\n    \"Plant\",\n    \"cost\",\n    \"Plant 1\",\n    50.0;\n    date_time = DateTime(2020, 1, 1),\n    stage = 1,\n)\n\n# Update existing time series value (same dimensions)\nPSRDatabase.add_time_series_row!(\n    db,\n    \"Plant\",\n    \"generation\",\n    \"Plant 1\",\n    120.0;\n    date_time = DateTime(2020, 1, 1),  # This will update the existing value\n)\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PSRDatabase.create_element!-Tuple{PSRDatabase.DatabaseSQLite, String}","page":"API Reference","title":"PSRDatabase.create_element!","text":"create_element!(db::DatabaseSQLite, collection_id::String; kwargs...)\n\nCreate a new element in the specified collection with the given attributes.\n\nArguments\n\ndb::DatabaseSQLite: The database connection\ncollection_id::String: The identifier of the collection to add the element to\nkwargs...: Named arguments specifying the attribute values for the new element\nScalar parameters: Single values (Int, Float64, String, DateTime)\nVector parameters: Arrays of values that must all have the same length within a group\nScalar relations: String labels of related elements or integer IDs\nVector relations: Arrays of string labels of related elements\nTime series: File paths as strings\n\nReturns\n\nnothing\n\nThrows\n\nDatabaseException if the collection doesn't exist\nDatabaseException if an attribute doesn't exist or has invalid type\nDatabaseException if vector parameters in the same group have different lengths\nDatabaseException if a required attribute is missing (e.g., label)\nSQLiteException if a label already exists (violates unique constraint)\n\nExamples\n\n# Create element with scalar parameters\nPSRDatabase.create_element!(db, \"Configuration\"; label = \"Toy Case\", value1 = 1.0)\n\n# Create element with vector parameters\nPSRDatabase.create_element!(\n    db,\n    \"Resource\";\n    label = \"Resource 1\",\n    type = \"E\",\n    some_value = [1.0, 2.0, 3.0],\n)\n\n# Create element with scalar relation (using label)\nPSRDatabase.create_element!(db, \"Plant\"; label = \"Plant 1\", capacity = 50.0, resource_id = \"Resource 1\")\n\n# Create element with vector relations\nPSRDatabase.create_element!(\n    db,\n    \"Process\";\n    label = \"Sugar Mill\",\n    product_input = [\"Sugarcane\"],\n    factor_input = [1.0],\n    product_output = [\"Sugar\", \"Molasse\", \"Bagasse\"],\n    factor_output = [0.3, 0.3, 0.4],\n)\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PSRDatabase.UPDATE_METHODS_BY_CLASS_OF_ATTRIBUTE","page":"API Reference","title":"PSRDatabase.UPDATE_METHODS_BY_CLASS_OF_ATTRIBUTE","text":"const UPDATE_METHODS_BY_CLASS_OF_ATTRIBUTE\n\nA dictionary mapping attribute classes to their corresponding update method names in PSRDatabase.\n\n\n\n\n\n","category":"constant"},{"location":"api_reference/#PSRDatabase.set_scalar_relation!-Tuple{PSRDatabase.DatabaseSQLite, Vararg{String, 5}}","page":"API Reference","title":"PSRDatabase.set_scalar_relation!","text":"set_scalar_relation!(db::DatabaseSQLite, collection_from::String, collection_to::String, label_collection_from::String, label_collection_to::String, relation_type::String)\n\nSet a scalar relation between two elements, linking an element from one collection to an element in another collection (or the same collection).\n\nArguments\n\ndb::DatabaseSQLite: The database connection\ncollection_from::String: The identifier of the collection containing the element to set the relation from\ncollection_to::String: The identifier of the collection containing the element to set the relation to\nlabel_collection_from::String: The label of the element to set the relation from\nlabel_collection_to::String: The label of the element to set the relation to\nrelation_type::String: The type/name of the relation (e.g., \"id\", \"turbineto\", \"spillto\")\n\nReturns\n\nnothing\n\nThrows\n\nDatabaseException if the attribute is not a scalar relation\nDatabaseException if either element label doesn't exist\nDatabaseException if trying to set a relation between the same element (when both collections are the same)\nDatabaseException if the relation type doesn't exist\n\nExamples\n\n# Set a relation to a different collection\nPSRDatabase.set_scalar_relation!(\n    db,\n    \"Plant\",\n    \"Resource\",\n    \"Plant 1\",\n    \"Resource 1\",\n    \"id\",\n)\n\n# Set a relation within the same collection\nPSRDatabase.set_scalar_relation!(\n    db,\n    \"Plant\",\n    \"Plant\",\n    \"Plant 3\",\n    \"Plant 1\",\n    \"turbine_to\",\n)\n\n# Update an existing relation\nPSRDatabase.set_scalar_relation!(\n    db,\n    \"Plant\",\n    \"Resource\",\n    \"Plant 1\",\n    \"Resource 2\",  # Changes from Resource 1 to Resource 2\n    \"id\",\n)\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PSRDatabase.set_time_series_file!-Tuple{PSRDatabase.DatabaseSQLite, String}","page":"API Reference","title":"PSRDatabase.set_time_series_file!","text":"set_time_series_file!(db::DatabaseSQLite, collection_id::String; kwargs...)\n\nSet or update time series file paths for a collection.\n\nThis function sets the file paths for time series attributes that store their data in external files. There can only be one set of time series files per collection.\n\nArguments\n\ndb::DatabaseSQLite: The database connection\ncollection_id::String: The identifier of the collection to set time series files for\nkwargs...: Named arguments where keys are time series file attribute names and values are file paths (strings)\n\nReturns\n\nnothing\n\nThrows\n\nDatabaseException if the collection doesn't exist\nDatabaseException if any attribute is not a time series file attribute\nDatabaseException if any value is not a string\nDatabaseException if there are multiple time series file entries (database corruption)\n\nExamples\n\n# Set time series files for a collection\nPSRDatabase.set_time_series_file!(\n    db,\n    \"Plant\";\n    generation = \"generation_data.csv\",\n    cost = \"cost_data.csv\",\n)\n\n# Update a single time series file\nPSRDatabase.set_time_series_file!(\n    db,\n    \"Plant\";\n    generation = \"new_generation_data.csv\",\n)\n\n# Set multiple time series files at once\nPSRDatabase.set_time_series_file!(\n    db,\n    \"Resource\";\n    availability = \"availability.txt\",\n    price = \"price.txt\",\n)\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PSRDatabase.set_vector_relation!-Tuple{PSRDatabase.DatabaseSQLite, String, String, String, Vector{String}, String}","page":"API Reference","title":"PSRDatabase.set_vector_relation!","text":"set_vector_relation!(db::DatabaseSQLite, collection_from::String, collection_to::String, label_collection_from::String, labels_collection_to::Vector{String}, relation_type::String)\n\nSet a vector relation between an element and multiple elements, linking an element from one collection to multiple elements in another collection.\n\nThis function replaces all existing relations for the vector with the new relations provided.\n\nArguments\n\ndb::DatabaseSQLite: The database connection\ncollection_from::String: The identifier of the collection containing the element to set the relation from\ncollection_to::String: The identifier of the collection containing the elements to set the relation to\nlabel_collection_from::String: The label of the element to set the relation from\nlabels_collection_to::Vector{String}: A vector of labels of elements to set the relation to\nrelation_type::String: The type/name of the relation\n\nReturns\n\nnothing\n\nThrows\n\nDatabaseException if the attribute is not a vector relation\nDatabaseException if any element label doesn't exist\nDatabaseException if the relation type doesn't exist\nDatabaseException if the number of relations doesn't match other vectors in the same group\n\nExamples\n\n# Set a vector relation\nPSRDatabase.set_vector_relation!(\n    db,\n    \"Plant\",\n    \"Cost\",\n    \"Plant 1\",\n    [\"Cost 1\", \"Cost 2\"],\n    \"some_relation_type\",\n)\n\n# Update vector relation with different elements\nPSRDatabase.set_vector_relation!(\n    db,\n    \"Plant\",\n    \"Cost\",\n    \"Plant 1\",\n    [\"Cost 2\", \"Cost 3\", \"Cost 4\"],  # Now relates to 3 costs instead of 2\n    \"some_relation_type\",\n)\n\n# Clear all relations (empty vector)\nPSRDatabase.set_vector_relation!(\n    db,\n    \"Plant\",\n    \"Cost\",\n    \"Plant 1\",\n    String[],\n    \"some_relation_type\",\n)\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PSRDatabase.update_parameter!-Tuple{PSRDatabase.DatabaseSQLite, String, String}","page":"API Reference","title":"PSRDatabase.update_parameter!","text":"update_parameter!(db::DatabaseSQLite, collection_id::String, label::String; kwargs...)\n\nUpdate multiple parameter attributes for a specific element in a collection. The function can update multiple types of parameters\n\nArguments\n\ndb::DatabaseSQLite: The database connection\ncollection_id::String: The identifier of the collection containing the element\nlabel::String: The label of the element to update\nkwargs...: Named arguments where keys are attribute names and values are the new values for those attributes\n\nReturns\n\n- `nothing`\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PSRDatabase.update_scalar_parameter!-Tuple{PSRDatabase.DatabaseSQLite, String, String, String, Any}","page":"API Reference","title":"PSRDatabase.update_scalar_parameter!","text":"update_scalar_parameter!(db::DatabaseSQLite, collection_id::String, attribute_id::String, label::String, val)\n\nUpdate the value of a scalar parameter attribute for a specific element in a collection.\n\nArguments\n\ndb::DatabaseSQLite: The database connection\ncollection_id::String: The identifier of the collection containing the element\nattribute_id::String: The identifier of the scalar parameter attribute to update\nlabel::String: The label of the element to update\nval: The new value for the attribute (must match the attribute's type: Float64, Int64, String, or DateTime)\n\nReturns\n\nnothing\n\nThrows\n\nDatabaseException if the collection or attribute doesn't exist\nDatabaseException if the attribute is not a scalar parameter\nDatabaseException if the value type doesn't match the attribute type\nDatabaseException if the element label doesn't exist\n\nExamples\n\n# Update a string parameter\nPSRDatabase.update_scalar_parameter!(db, \"Resource\", \"type\", \"Resource 1\", \"D\")\n\n# Update a numeric parameter\nPSRDatabase.update_scalar_parameter!(db, \"Resource\", \"some_value_1\", \"Resource 1\", 1.0)\n\n# Update a date parameter\nPSRDatabase.update_scalar_parameter!(db, \"Configuration\", \"date_initial\", \"Toy Case\", DateTime(2021, 1, 1))\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PSRDatabase.update_time_series_row!-Tuple{PSRDatabase.DatabaseSQLite, String, String, String, Any}","page":"API Reference","title":"PSRDatabase.update_time_series_row!","text":"update_time_series_row!(db::DatabaseSQLite, collection_id::String, attribute_id::String, label::String, val; dimensions...)\n\nUpdate an existing value in a time series attribute for a specific element and dimension combination.\n\nUnlike add_time_series_row!, this function only updates existing rows and will throw an error if the specified dimension combination doesn't exist.\n\nArguments\n\ndb::DatabaseSQLite: The database connection\ncollection_id::String: The identifier of the collection containing the element\nattribute_id::String: The identifier of the time series attribute\nlabel::String: The label of the element to update the time series value for\nval: The new value for the time series at the specified dimensions\ndimensions...: Named arguments specifying the dimension values that identify the row to update\n\nReturns\n\nnothing\n\nThrows\n\nDatabaseException if the attribute is not a time series\nDatabaseException if the number of dimensions doesn't match the attribute definition\nDatabaseException if dimension names don't match the attribute definition\nDatabaseException if the specified dimension combination doesn't exist\n\nExamples\n\n# Update an existing time series value\nPSRDatabase.update_time_series_row!(\n    db,\n    \"Plant\",\n    \"generation\",\n    \"Plant 1\",\n    150.0;\n    date_time = DateTime(2020, 1, 1),\n)\n\n# Update with multiple dimensions\nPSRDatabase.update_time_series_row!(\n    db,\n    \"Plant\",\n    \"cost\",\n    \"Plant 1\",\n    75.0;\n    date_time = DateTime(2020, 1, 1),\n    stage = 1,\n)\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PSRDatabase.update_vector_parameters!-Tuple{PSRDatabase.DatabaseSQLite, String, String, String, Vector}","page":"API Reference","title":"PSRDatabase.update_vector_parameters!","text":"update_vector_parameters!(db::DatabaseSQLite, collection_id::String, attribute_id::String, label::String, vals::Vector)\n\nUpdate all values of a vector parameter attribute for a specific element in a collection.\n\nThis function replaces all existing values for the vector with the new values provided.\n\nArguments\n\ndb::DatabaseSQLite: The database connection\ncollection_id::String: The identifier of the collection containing the element\nattribute_id::String: The identifier of the vector parameter attribute to update\nlabel::String: The label of the element to update\nvals::Vector: A vector containing the new values (must match the attribute's type)\n\nReturns\n\nnothing\n\nThrows\n\nDatabaseException if the collection or attribute doesn't exist\nDatabaseException if the attribute is not a vector parameter\nDatabaseException if the value types don't match the attribute type\nDatabaseException if the element label doesn't exist\nDatabaseException if updating vectors in a group and the new length doesn't match other vectors in the group\n\nExamples\n\n# Update a vector of numeric values\nPSRDatabase.update_vector_parameters!(\n    db,\n    \"Resource\",\n    \"some_value_1\",\n    \"Resource 1\",\n    [10.0, 20.0, 30.0],\n)\n\n# Update to a different number of values (if not constrained by vector group)\nPSRDatabase.update_vector_parameters!(\n    db,\n    \"Resource\",\n    \"some_value_1\",\n    \"Resource 1\",\n    [5.0, 15.0],\n)\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PSRDatabase.delete_element!-Tuple{PSRDatabase.DatabaseSQLite, String, Integer}","page":"API Reference","title":"PSRDatabase.delete_element!","text":"delete_element!(db::DatabaseSQLite, collection_id::String, id::Integer)\n\nDelete an element from a collection by its numeric ID.\n\nThis function removes an element and all its associated data from the database. Due to CASCADE DELETE foreign key constraints, any references to this element from other collections will also be deleted.\n\nArguments\n\ndb::DatabaseSQLite: The database connection\ncollection_id::String: The identifier of the collection containing the element\nid::Integer: The numeric ID of the element to delete\n\nReturns\n\nnothing\n\nExamples\n\n# Delete an element by ID\nPSRDatabase.delete_element!(db, \"Plant\", 3)\n\n# Typically used internally after looking up an ID from a label\nid = PSRDatabase._get_id(db, \"Plant\", \"Plant 1\")\nPSRDatabase.delete_element!(db, \"Plant\", id)\n\nSee Also\n\ndelete_element!(db, collection_id, label): Delete by label instead of numeric ID\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PSRDatabase.delete_element!-Tuple{PSRDatabase.DatabaseSQLite, String, String}","page":"API Reference","title":"PSRDatabase.delete_element!","text":"delete_element!(db::DatabaseSQLite, collection_id::String, label::String)\n\nDelete an element from a collection by its label.\n\nThis function removes an element and all its associated data from the database. Due to CASCADE DELETE foreign key constraints, any references to this element from other collections will also be deleted.\n\nArguments\n\ndb::DatabaseSQLite: The database connection\ncollection_id::String: The identifier of the collection containing the element\nlabel::String: The label of the element to delete\n\nReturns\n\nnothing\n\nThrows\n\nDatabaseException if the collection doesn't exist\nDatabaseException if the element label doesn't exist\nSQLiteException if the deletion violates database constraints (e.g., foreign key without cascade)\n\nExamples\n\n# Delete an element by label\nPSRDatabase.delete_element!(db, \"Plant\", \"Plant 3\")\n\n# After deletion, the same label can be reused\nPSRDatabase.create_element!(db, \"Plant\"; label = \"Plant 3\", capacity = 100.0)\n\n# Deleting an element that has relations will also delete those relations\nPSRDatabase.delete_element!(db, \"Resource\", \"Resource 1\")  # Also removes Plant->Resource relations\n\nSee Also\n\ndelete_element!(db, collection_id, id): Delete by numeric ID instead of label\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PSRDatabase.delete_time_series!-Tuple{PSRDatabase.DatabaseSQLite, String, String, String}","page":"API Reference","title":"PSRDatabase.delete_time_series!","text":"delete_time_series!(db::DatabaseSQLite, collection_id::String, group_id::String, label::String)\n\nDelete all time series data for a specific element in a time series group.\n\nThis function removes all rows from the time series table for a given element, effectively deleting all time series values across all dimensions for that element and group.\n\nArguments\n\ndb::DatabaseSQLite: The database connection\ncollection_id::String: The identifier of the collection containing the element\ngroup_id::String: The identifier of the time series group\nlabel::String: The label of the element to delete time series data for\n\nReturns\n\nnothing\n\nThrows\n\nDatabaseException if the collection doesn't exist\nDatabaseException if the element label doesn't exist\n\nExamples\n\n# Delete all time series data for an element in a specific group\nPSRDatabase.delete_time_series!(db, \"Plant\", \"generation_group\", \"Plant 1\")\n\n# After deletion, you can add new time series data for the same element\nPSRDatabase.add_time_series_row!(\n    db,\n    \"Plant\",\n    \"generation\",\n    \"Plant 1\",\n    100.0;\n    date_time = DateTime(2021, 1, 1),\n)\n\nNotes\n\nThis function only deletes time series data, not the element itself. To delete the entire element, use delete_element! instead.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PSRDatabase.create_empty_db_from_migrations-Tuple{String, String}","page":"API Reference","title":"PSRDatabase.create_empty_db_from_migrations","text":"create_empty_db_from_migrations(database_path::String, path_migrations::String; force::Bool = false)\n\nCreate a new empty database by applying migration files.\n\nThis function creates a new SQLite database file and applies all migration files found in the specified directory to build up the database structure incrementally.\n\nArguments\n\ndatabase_path::String: The file path where the database will be created\npath_migrations::String: The path to the directory containing migration SQL files\nforce::Bool: If true, overwrites an existing database file at the same path. If false (default), throws an error if the file already exists\n\nReturns\n\nDatabaseSQLite: A database connection object to the newly created database\n\nThrows\n\nDatabaseException if the database file already exists and force=false\nDatabaseException if the migrations directory is not found or migrations are invalid\nDatabaseException if the resulting database structure is invalid\nSQLiteException if SQL statements in migrations are invalid\n\nExamples\n\n# Create a new database from migrations\ndb = PSRDatabase.create_empty_db_from_migrations(\n    \"my_database.sqlite\",\n    \"migrations/\",\n)\n\n# Overwrite existing database\ndb = PSRDatabase.create_empty_db_from_migrations(\n    \"my_database.sqlite\",\n    \"migrations/\";\n    force = true,\n)\n\nSee Also\n\ncreate_empty_db_from_schema: Create database from a single schema file\nload_db: Load and migrate an existing database\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PSRDatabase.create_empty_db_from_schema-Tuple{String, String}","page":"API Reference","title":"PSRDatabase.create_empty_db_from_schema","text":"create_empty_db_from_schema(database_path::String, path_schema::String; force::Bool = false)\n\nCreate a new empty database from a SQL schema file.\n\nThis function creates a new SQLite database file and executes all SQL statements from the schema file to set up the database structure (tables, constraints, etc.).\n\nArguments\n\ndatabase_path::String: The file path where the database will be created\npath_schema::String: The path to the SQL schema file containing CREATE TABLE statements\nforce::Bool: If true, overwrites an existing database file at the same path. If false (default), throws an error if the file already exists\n\nReturns\n\nDatabaseSQLite: A database connection object to the newly created database\n\nThrows\n\nDatabaseException if the database file already exists and force=false\nDatabaseException if the schema file is not found\nDatabaseException if the database structure is invalid (e.g., missing Configuration table)\nSQLiteException if SQL statements in the schema are invalid\n\nExamples\n\n# Create a new database from a schema file\ndb = PSRDatabase.create_empty_db_from_schema(\n    \"my_database.sqlite\",\n    \"schema.sql\",\n)\n\n# Overwrite existing database\ndb = PSRDatabase.create_empty_db_from_schema(\n    \"my_database.sqlite\",\n    \"schema.sql\";\n    force = true,\n)\n\nSee Also\n\ncreate_empty_db_from_migrations: Create database using migration files\nload_db: Load an existing database\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PSRDatabase.execute_statements-Tuple{SQLite.DB, String}","page":"API Reference","title":"PSRDatabase.execute_statements","text":"execute_statements(db::SQLite.DB, file::String)\n\nExecute all statements in a .sql file against a database.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PSRDatabase.load_db-Tuple{String, String}","page":"API Reference","title":"PSRDatabase.load_db","text":"load_db(database_path::String, path_migrations::String)\n\nLoad an existing database and apply any pending migrations.\n\nOpens a connection to an existing SQLite database file and applies any migration files that haven't been applied yet.\n\nArguments\n\ndatabase_path::String: The file path to the database to load\npath_migrations::String: The path to the directory containing migration SQL files\n\nReturns\n\nDatabaseSQLite: A database connection object with all migrations applied\n\nThrows\n\nDatabaseException if the database file doesn't exist\nDatabaseException if migrations are invalid or cannot be applied\nSQLiteException if the file is not a valid SQLite database or migration SQL is invalid\n\nExamples\n\n# Load a database and apply pending migrations\ndb = PSRDatabase.load_db(\"my_database.sqlite\", \"migrations/\")\n\n# Work with the database\nlabels = PSRDatabase.read_scalar_parameters(db, \"Plant\", \"label\")\n\n# Close when done\nPSRDatabase.close!(db)\n\nSee Also\n\nload_db(database_path; read_only): Load without applying migrations\ncreate_empty_db_from_migrations: Create new database with migrations\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PSRDatabase.load_db-Tuple{String}","page":"API Reference","title":"PSRDatabase.load_db","text":"load_db(database_path::String; read_only::Bool = false)\n\nLoad an existing database from a file.\n\nOpens a connection to an existing SQLite database file. The database structure is validated and metadata is loaded into memory for fast access.\n\nArguments\n\ndatabase_path::String: The file path to the database to load\nread_only::Bool: If true, opens the database in read-only mode (immutable). If false (default), opens with read-write access\n\nReturns\n\nDatabaseSQLite: A database connection object\n\nThrows\n\nDatabaseException if the database file doesn't exist\nDatabaseException if the database structure is invalid\nSQLiteException if the file is not a valid SQLite database\n\nExamples\n\n# Load a database with read-write access\ndb = PSRDatabase.load_db(\"my_database.sqlite\")\n\n# Load a database in read-only mode\ndb = PSRDatabase.load_db(\"my_database.sqlite\"; read_only = true)\n\n# Use the database and close when done\nPSRDatabase.close!(db)\n\nSee Also\n\nload_db(database_path, path_migrations): Load and apply migrations\ncreate_empty_db_from_schema: Create a new database\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PSRDatabase._validate_database_pragmas-Tuple{SQLite.DB}","page":"API Reference","title":"PSRDatabase._validate_database_pragmas","text":"_validate_database_pragmas(db::SQLite.DB)\n\nInternal function to validate that required SQLite pragmas are properly set in the database.\n\nCurrently validates:\n\nUser version must be defined and not set to zero\n\nArguments\n\ndb::SQLite.DB: The SQLite database connection to validate\n\nReturns\n\nnothing\n\nThrows\n\nDatabaseException if user_version is 0 or not defined\n\nNotes\n\nThis is an internal validation function used during database loading to ensure the database has proper version information. The user_version pragma is used for schema versioning and migrations.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PSRDatabase.GroupMap","page":"API Reference","title":"PSRDatabase.GroupMap","text":"GroupMap\n\nInternal struct to store information about a time series group for docstring generation.\n\nFields\n\ngroup_id::String: The identifier of the time series group\nparameters::Vector{TimeSeries{<:Number}}: Vector of time series parameters in the group\ndimensions::Vector{String}: Names of the dimensions for this time series group\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#PSRDatabase.collection_docstring-Tuple{String, String}","page":"API Reference","title":"PSRDatabase.collection_docstring","text":"collection_docstring(model_folder::String, collection::String; ignore_id::Bool = true)\n\nGenerate automatic documentation for a collection's attributes.\n\nThis function creates documentation text that lists all required and optional parameters,  vector attributes, relations, and time series for a specific collection in a PSR model. It reads the database schema from migrations and attribute metadata from TOML files.\n\nArguments\n\nmodel_folder::String: Path to the model directory containing migrations and UI metadata\ncollection::String: Name of the collection to document\nignore_id::Bool: If true (default), excludes the id field from documentation\n\nReturns\n\nString: Formatted documentation string with all collection attributes\n\nExamples\n\n# Use in a model-specific add function to automatically generate parameter documentation\n\"\"\"\n    add_hydro_unit!(db::DatabaseSQLite; kwargs...)\n\nAdd a Hydro Unit to the database.\n\n# Arguments\n$(PSRDatabase.collection_docstring(model_directory(), \"HydroUnit\"))\n\n# Examples\n    db = PSRDatabase.load_db(\"path/to/model.db\")\n    add_hydro_unit!(\n        db;\n        label = \"Plant1\",\n        initial_volume = 100.0,\n    )\n\"\"\"\nfunction add_hydro_unit!(db::DatabaseSQLite; kwargs...)\n    PSRDatabase.create_element!(db, \"HydroUnit\"; kwargs...)\nend\n\nNotes\n\nCreates a temporary database from migrations to extract schema information. The temporary database is automatically cleaned up after generating the docstring.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PSRDatabase.time_series_files_docstrings","page":"API Reference","title":"PSRDatabase.time_series_files_docstrings","text":"time_series_files_docstrings(model_folder::String, ignore_id::Bool = true)\n\nGenerate documentation for all time series file attributes across all collections.\n\nThis function creates documentation text listing all time series file attributes organized by collection. It reads the database schema from migrations and attribute metadata from TOML files.\n\nArguments\n\nmodel_folder::String: Path to the model directory containing migrations and UI metadata\nignore_id::Bool: If true (default), excludes the id field from documentation\n\nReturns\n\nString: Formatted documentation string with all time series file attributes organized by collection\n\nExamples\n\n# Use in a model's link function to automatically document available time series files\n\"\"\"\n    link_time_series_to_file(db::DatabaseSQLite, table_name::String; kwargs...)\n\nLinks a time series to a file in the database.\n\nEach collection in the database can be linked to different time series files.\n\nThe possible files for each collection are:\n\n$(PSRDatabase.time_series_files_docstrings(model_directory()))\n\n# Examples\n    db = PSRDatabase.load_db(\"path/to/model.db\")\n    link_time_series_to_file(\n        db,\n        \"HydroUnit\";\n        file_path = \"generation.csv\",\n    )\n\"\"\"\nfunction link_time_series_to_file(db::DatabaseSQLite, table_name::String; kwargs...)\n    PSRDatabase.set_time_series_file!(db, table_name; kwargs...)\nend\n\nNotes\n\nCreates a temporary database from migrations to extract schema information. The temporary database is automatically cleaned up after generating the docstring.\n\n\n\n\n\n","category":"function"},{"location":"api_reference/#PSRDatabase.compare_databases-Tuple{PSRDatabase.DatabaseSQLite, PSRDatabase.DatabaseSQLite}","page":"API Reference","title":"PSRDatabase.compare_databases","text":"compare_databases(db1::DatabaseSQLite, db2::DatabaseSQLite)\n\nCompare two databases to ensure they have the same data across all collections.\n\nThis function performs a comprehensive comparison of two PSRDatabase databases by iterating through all collections and comparing their:\n\nNumber of elements\nScalar parameters\nVector parameters\nScalar relations\nVector relations\nTime series data\nTime series file references\n\nThe comparison is thorough and identifies specific differences at the element, attribute, and value level, making it useful for validating database migrations, testing database operations, or ensuring data consistency after transformations.\n\nArguments\n\ndb1::DatabaseSQLite: The first database to compare\ndb2::DatabaseSQLite: The second database to compare\n\nReturns\n\nA vector of strings describing all differences found. Each string is a human-readable error message that identifies:\n\nThe collection where the difference was found\nThe attribute or data type being compared\nThe specific element (by index or label)\nThe exact values that differ\n\nIf the databases are completely identical, returns an empty vector.\n\nExamples\n\n# Compare two identical databases\ndb1 = create_empty_db_from_schema(\"db1.sqlite\", \"schema.sql\"; force = true)\ndb2 = create_empty_db_from_schema(\"db2.sqlite\", \"schema.sql\"; force = true)\n\ncreate_element!(db1, \"Configuration\"; label = \"Config1\", value1 = 100.0)\ncreate_element!(db2, \"Configuration\"; label = \"Config1\", value1 = 100.0)\n\ndifferences = compare_databases(db1, db2)\n# Returns: []\n\n# Compare databases with differences\ndb3 = create_empty_db_from_schema(\"db3.sqlite\", \"schema.sql\"; force = true)\ndb4 = create_empty_db_from_schema(\"db4.sqlite\", \"schema.sql\"; force = true)\n\ncreate_element!(db3, \"Configuration\"; label = \"Config1\", value1 = 100.0)\ncreate_element!(db4, \"Configuration\"; label = \"Config1\", value1 = 200.0)\n\ndifferences = compare_databases(db3, db4)\n# Returns: [\"Collection 'Configuration', attribute 'value1', element 1: values differ (db1: 100.0, db2: 200.0)\"]\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PSRDatabase.compare_scalar_parameters-Tuple{PSRDatabase.DatabaseSQLite, PSRDatabase.DatabaseSQLite, String}","page":"API Reference","title":"PSRDatabase.compare_scalar_parameters","text":"compare_scalar_parameters(db1::DatabaseSQLite, db2::DatabaseSQLite, collection_id::String)\n\nCompare scalar parameters between two databases for a specific collection.\n\nThis function iterates through all scalar parameters (excluding the id field) in the specified collection and compares their values element-by-element between the two databases. It checks for differences in the number of elements, null values, and actual value mismatches.\n\nArguments\n\ndb1::DatabaseSQLite: The first database to compare (used as the reference for reading collection structure)\ndb2::DatabaseSQLite: The second database to compare against the first\ncollection_id::String: The name of the collection (table) to compare scalar parameters for\n\nReturns\n\nA vector of strings describing differences found in scalar parameters. Each string includes the collection name, attribute name, element index, and the differing values. Returns an empty vector if all scalar parameters are identical.\n\nExample\n\ndb1 = create_empty_db_from_schema(\"db1.sqlite\", \"schema.sql\"; force = true)\ndb2 = create_empty_db_from_schema(\"db2.sqlite\", \"schema.sql\"; force = true)\n\ncreate_element!(db1, \"Configuration\"; label = \"Config1\", value1 = 100.0)\ncreate_element!(db2, \"Configuration\"; label = \"Config1\", value1 = 200.0)\n\ndifferences = compare_scalar_parameters(db1, db2, \"Configuration\")\n# Returns: [\"Collection 'Configuration', attribute 'value1', element 1: values differ (db1: 100.0, db2: 200.0)\"]\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PSRDatabase.compare_scalar_relations-Tuple{PSRDatabase.DatabaseSQLite, PSRDatabase.DatabaseSQLite, String}","page":"API Reference","title":"PSRDatabase.compare_scalar_relations","text":"compare_scalar_relations(db1::DatabaseSQLite, db2::DatabaseSQLite, collection_id::String)\n\nCompare scalar relations between two databases for a specific collection.\n\nThis function iterates through all scalar relations (foreign key references to other collections) in the specified collection and compares them element-by-element between the two databases. It verifies that each element points to the same related element in both databases.\n\nArguments\n\ndb1::DatabaseSQLite: The first database to compare (used as the reference for reading collection structure)\ndb2::DatabaseSQLite: The second database to compare against the first\ncollection_id::String: The name of the collection (table) to compare scalar relations for\n\nReturns\n\nA vector of strings describing differences found in scalar relations. Each string includes the collection name, relation attribute name, target collection name, element index, and the labels of the related elements that differ. Returns an empty vector if all scalar relations are identical.\n\nExample\n\ndb1 = create_empty_db_from_schema(\"db1.sqlite\", \"schema.sql\"; force = true)\ndb2 = create_empty_db_from_schema(\"db2.sqlite\", \"schema.sql\"; force = true)\n\n# Create resources\ncreate_element!(db1, \"Resource\"; label = \"Resource1\", type = \"D\")\ncreate_element!(db1, \"Resource\"; label = \"Resource2\", type = \"E\")\ncreate_element!(db2, \"Resource\"; label = \"Resource1\", type = \"D\")\ncreate_element!(db2, \"Resource\"; label = \"Resource2\", type = \"E\")\n\n# Create plants with different scalar relations\ncreate_element!(db1, \"Plant\"; label = \"Plant1\", capacity = 100.0)\ncreate_element!(db2, \"Plant\"; label = \"Plant1\", capacity = 100.0)\nset_scalar_relation!(db1, \"Plant\", \"Resource\", \"Plant1\", \"Resource1\", \"id\")\nset_scalar_relation!(db2, \"Plant\", \"Resource\", \"Plant1\", \"Resource2\", \"id\")\n\ndifferences = compare_scalar_relations(db1, db2, \"Plant\")\n# Returns: [\"Collection 'Plant', scalar relation 'resource_id' to 'Resource', element 1: relations differ (db1: Resource1, db2: Resource2)\"]\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PSRDatabase.compare_time_series-Tuple{PSRDatabase.DatabaseSQLite, PSRDatabase.DatabaseSQLite, String}","page":"API Reference","title":"PSRDatabase.compare_time_series","text":"compare_time_series(db1::DatabaseSQLite, db2::DatabaseSQLite, collection_id::String)\n\nCompare time series data between two databases for a specific collection.\n\nThis function iterates through all time series attributes in the specified collection, grouped by their group_id, and compares the data for each element between the two databases. For each time series, it checks:\n\nThe size of the time series tables (number of rows and columns)\nThe column names and their order\nIndividual values in each cell of the time series data\n\nThe comparison handles missing values and null values appropriately, ensuring that null states match between databases.\n\nArguments\n\ndb1::DatabaseSQLite: The first database to compare (used as the reference for reading collection structure and element labels)\ndb2::DatabaseSQLite: The second database to compare against the first\ncollection_id::String: The name of the collection (table) to compare time series data for\n\nReturns\n\nA vector of strings describing differences found in time series data. Each string includes the collection name, time series attribute name, element label, column name, row index, and the differing values. Returns an empty vector if all time series data is identical.\n\nExample\n\nusing DataFrames, Dates\n\ndb1 = create_empty_db_from_schema(\"db1.sqlite\", \"schema.sql\"; force = true)\ndb2 = create_empty_db_from_schema(\"db2.sqlite\", \"schema.sql\"; force = true)\n\ndf1 = DataFrame(\n    date_time = [DateTime(2020), DateTime(2021), DateTime(2022)],\n    some_vector1 = [1.0, 2.0, 3.0],\n    some_vector2 = [10.0, 20.0, 30.0],\n)\ndf2 = DataFrame(\n    date_time = [DateTime(2020), DateTime(2021), DateTime(2022)],\n    some_vector1 = [1.0, 5.0, 3.0],\n    some_vector2 = [10.0, 20.0, 30.0],\n)\n\ncreate_element!(db1, \"Resource\"; label = \"Resource1\", type = \"D\", group1 = df1)\ncreate_element!(db2, \"Resource\"; label = \"Resource1\", type = \"D\", group1 = df2)\n\ndifferences = compare_time_series(db1, db2, \"Resource\")\n# Returns: [\"Collection 'Resource', time series 'some_vector1', label 'Resource1', column 'some_vector1', row 2: values differ (db1: 2.0, db2: 5.0)\"]\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PSRDatabase.compare_time_series_files-Tuple{PSRDatabase.DatabaseSQLite, PSRDatabase.DatabaseSQLite, String}","page":"API Reference","title":"PSRDatabase.compare_time_series_files","text":"compare_time_series_files(db1::DatabaseSQLite, db2::DatabaseSQLite, collection_id::String)\n\nCompare time series file paths between two databases for a specific collection.\n\nThis function compares the file paths stored in the timeseriesfiles table for each element in the specified collection. It checks whether file paths are present in one database but not the other, and whether the file paths match when present in both databases.\n\nNote that this function only compares the file path strings stored in the database, not the contents of the files themselves.\n\nArguments\n\ndb1::DatabaseSQLite: The first database to compare (used as the reference for reading collection structure and element labels)\ndb2::DatabaseSQLite: The second database to compare against the first\ncollection_id::String: The name of the collection (table) to compare time series file references for\n\nReturns\n\nA vector of strings describing differences found in time series file paths. Each string includes the collection name, time series file attribute name, and information about whether file paths are missing or differ between databases. Returns an empty vector if all time series file references are identical.\n\nExample\n\ndb1 = create_empty_db_from_schema(\"db1.sqlite\", \"schema.sql\"; force = true)\ndb2 = create_empty_db_from_schema(\"db2.sqlite\", \"schema.sql\"; force = true)\n\ncreate_element!(db1, \"Plant\"; label = \"Plant1\", capacity = 100.0)\ncreate_element!(db2, \"Plant\"; label = \"Plant1\", capacity = 100.0)\n\nset_time_series_file!(db1, \"Plant\"; generation = \"generation1.csv\")\nset_time_series_file!(db2, \"Plant\"; generation = \"generation2.csv\")\n\ndifferences = compare_time_series_files(db1, db2, \"Plant\")\n# Returns: [\"Collection 'Plant', time series file 'generation': file paths differ (db1: generation1.csv, db2: generation2.csv)\"]\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PSRDatabase.compare_vector_parameters-Tuple{PSRDatabase.DatabaseSQLite, PSRDatabase.DatabaseSQLite, String}","page":"API Reference","title":"PSRDatabase.compare_vector_parameters","text":"compare_vector_parameters(db1::DatabaseSQLite, db2::DatabaseSQLite, collection_id::String)\n\nCompare vector parameters between two databases for a specific collection.\n\nThis function iterates through all vector parameters in the specified collection and compares their values element-by-element between the two databases. For each vector attribute, it checks:\n\nThe number of elements in the collection\nThe length of each vector\nIndividual values within each vector\n\nArguments\n\ndb1::DatabaseSQLite: The first database to compare (used as the reference for reading collection structure)\ndb2::DatabaseSQLite: The second database to compare against the first\ncollection_id::String: The name of the collection (table) to compare vector parameters for\n\nReturns\n\nA vector of strings describing differences found in vector parameters. Each string includes the collection name, vector attribute name, element index, vector index, and the differing values. Returns an empty vector if all vector parameters are identical.\n\nExample\n\ndb1 = create_empty_db_from_schema(\"db1.sqlite\", \"schema.sql\"; force = true)\ndb2 = create_empty_db_from_schema(\"db2.sqlite\", \"schema.sql\"; force = true)\n\ncreate_element!(db1, \"Resource\"; label = \"Resource1\", type = \"D\", some_value1 = [1.0, 2.0, 3.0])\ncreate_element!(db2, \"Resource\"; label = \"Resource1\", type = \"D\", some_value1 = [1.0, 5.0, 3.0])\n\ndifferences = compare_vector_parameters(db1, db2, \"Resource\")\n# Returns: [\"Collection 'Resource', vector attribute 'some_value1', element 1, index 2: values differ (db1: 2.0, db2: 5.0)\"]\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PSRDatabase.compare_vector_relations-Tuple{PSRDatabase.DatabaseSQLite, PSRDatabase.DatabaseSQLite, String}","page":"API Reference","title":"PSRDatabase.compare_vector_relations","text":"compare_vector_relations(db1::DatabaseSQLite, db2::DatabaseSQLite, collection_id::String)\n\nCompare vector relations between two databases for a specific collection.\n\nThis function iterates through all vector relations (arrays of foreign key references to other collections) in the specified collection and compares them element-by-element between the two databases. For each vector relation, it checks:\n\nThe number of elements in the collection\nThe length of each relation vector\nIndividual relation references within each vector\n\nArguments\n\ndb1::DatabaseSQLite: The first database to compare (used as the reference for reading collection structure)\ndb2::DatabaseSQLite: The second database to compare against the first\ncollection_id::String: The name of the collection (table) to compare vector relations for\n\nReturns\n\nA vector of strings describing differences found in vector relations. Each string includes the collection name, vector relation attribute name, target collection name, element index, vector index, and the labels of the related elements that differ. Returns an empty vector if all vector relations are identical.\n\nExample\n\ndb1 = create_empty_db_from_schema(\"db1.sqlite\", \"schema.sql\"; force = true)\ndb2 = create_empty_db_from_schema(\"db2.sqlite\", \"schema.sql\"; force = true)\n\n# Create costs\nfor (db, label, value) in [(db1, \"Cost1\", 10.0), (db1, \"Cost2\", 20.0), (db1, \"Cost3\", 30.0),\n                            (db2, \"Cost1\", 10.0), (db2, \"Cost2\", 20.0), (db2, \"Cost3\", 30.0)]\n    create_element!(db, \"Cost\"; label = label, value = value)\nend\n\n# Create plants with different vector relations\ncreate_element!(db1, \"Plant\"; label = \"Plant1\", capacity = 100.0, some_factor = [1.0, 2.0])\ncreate_element!(db2, \"Plant\"; label = \"Plant1\", capacity = 100.0, some_factor = [1.0, 2.0])\nset_vector_relation!(db1, \"Plant\", \"Cost\", \"Plant1\", [\"Cost1\", \"Cost2\"], \"id\")\nset_vector_relation!(db2, \"Plant\", \"Cost\", \"Plant1\", [\"Cost1\", \"Cost3\"], \"id\")\n\ndifferences = compare_vector_relations(db1, db2, \"Plant\")\n# Returns: [\"Collection 'Plant', vector relation 'cost_id' to 'Cost', element 1, index 2: relations differ (db1: Cost2, db2: Cost3)\"]\n\n\n\n\n\n","category":"method"},{"location":"psrdatabase/rules/#PSRDatabase","page":"PSRDatabase","title":"PSRDatabase","text":"SQL schemas for the PSRDatabase framework should follow the conventions described in this document. Note that this is a tool for creating and developing some kinds of applications. Not all tools will need to use this framework.","category":"section"},{"location":"psrdatabase/rules/#SQL-Schema-Conventions","page":"PSRDatabase","title":"SQL Schema Conventions","text":"","category":"section"},{"location":"psrdatabase/rules/#Collections","page":"PSRDatabase","title":"Collections","text":"The Table name should be the same as the name of the Collection.\nThe Table name of a Collection should beging with a capital letter and be in singular form.\nIn case of a Collection with a composite name, the Table name should written in Pascal Case.\nThe Table must contain a primary key named id that is an INTEGER. You should use the AUTOINCREMENT keyword to automatically generate the id for each element.\n\nExamples:\n\nCREATE TABLE Resource (\n    id INTEGER PRIMARY KEY AUTOINCREMENT,\n    label TEXT UNIQUE NOT NULL,\n    some_type TEXT\n) STRICT;\n\nCREATE TABLE ThermalPlant(\n    id INTEGER PRIMARY KEY AUTOINCREMENT,\n    label TEXT UNIQUE NOT NULL,\n    minimum_generation REAL DEFAULT 0\n) STRICT;","category":"section"},{"location":"psrdatabase/rules/#Configuration-collection","page":"PSRDatabase","title":"Configuration collection","text":"Every database definition must have a Configuration, which will store information from the case.  The column label is not mandatory for a Configuration collection.\n\nCREATE TABLE Configuration (\n    id INTEGER PRIMARY KEY AUTOINCREMENT,\n    value1 REAL NOT NULL DEFAULT 100,\n) STRICT;","category":"section"},{"location":"psrdatabase/rules/#Scalar-Attributes","page":"PSRDatabase","title":"Scalar Attributes","text":"The name of an Attribute should be in snake case and be in singular form.\nIf the attribute's name is label, it should be stored as a TEXT and have the UNIQUE and NOT NULL constraints.\n\nExample:\n\nCREATE TABLE ThermalPlant(\n    id INTEGER PRIMARY KEY AUTOINCREMENT,\n    label TEXT UNIQUE NOT NULL,\n    minimum_generation REAL NOT NULL\n    some_example_of_attribute REAL\n) STRICT;\n\nIf an attribute name starts with date it should be stored as a TEXT and indicates a date that will be mapped to a DateTime object.\n\nExample:\n\nCREATE TABLE ThermalPlant(\n    id INTEGER PRIMARY KEY AUTOINCREMENT,\n    label TEXT UNIQUE NOT NULL,\n    minimum_generation REAL NOT NULL,\n    date_of_construction TEXT\n) STRICT;\n\nA relation with another collection should be stored as an attribute whose name is the name of the target collection followed by the relation type defined as _relation_type, i.e. collectionname_relation_type. The relation attribute name starts with the name of another collection it should be stored as a INTEGER and indicates a relation with another collection. It should never have the NOT NULL constraint. All references should always declare the ON UPDATE CASCADE ON DELETE CASCADE constraint. In the example below the attribute gaugingstation_id indicates that the collection Plant has an id relation with the collection GaugingStation and the attribute plant_spill_to indicates that the collection Plant has a spill_to relation with itself.\n\nExample:\n\nCREATE TABLE Plant(\n    id INTEGER PRIMARY KEY AUTOINCREMENT,\n    label TEXT UNIQUE NOT NULL,\n    capacity REAL NOT NULL,\n    gaugingstation_id INTEGER,\n    plant_spill_to INTEGER,\n    FOREIGN KEY(gaugingstation_id) REFERENCES GaugingStation(id) ON UPDATE CASCADE ON DELETE CASCADE,\n    FOREIGN KEY(plant_spill_to) REFERENCES Plant(id) ON UPDATE SET NULL ON DELETE CASCADE\n) STRICT;","category":"section"},{"location":"psrdatabase/rules/#Vector-Attributes","page":"PSRDatabase","title":"Vector Attributes","text":"In case of a vector attribute, a table should be created with its name indicating the name of the Collection and the name of a group of the attribute, separated by _vector_, such as COLLECTION_vector_GROUP_OF_ATTRIBUTES.\nThe table must contain a Column named id and another named vector_index. These two columns together should form the Primary Key of the table.\nThere must be a Column named after the attributes names, which will store the value of the attribute for the specified element id and index vector_index.\n\nThese groups are used to store vectors that should have the same size. If two vectors don't necessarily have the same size, they should be stored in different groups.\n\nExample:\n\nCREATE TABLE ThermalPlant_vector_some_group(\n    id INTEGER,\n    vector_index INTEGER NOT NULL,\n    some_value REAL NOT NULL,\n    some_other_value REAL,\n    FOREIGN KEY (id) REFERENCES ThermalPlant(id) ON UPDATE CASCADE ON DELETE CASCADE,\n    PRIMARY KEY (id, vector_index)\n) STRICT;\n\nA vector relation with another collection should be stored in a table of vector groups and be defined the same way as a vector attribute. To tell that it is a relation with another collection, the name of the relational attribute should be the name of the target collection followed by the relation type defined as _relation_type, i.e. gaugingstation_id indicated that the collection HydroPlant has an id relation with the collection GaugingStation. If the name of the attribute was gaugingstation_turbine_to, it would indicate that the collection HydroPlant has a relation turbine_to with the collection GaugingStation.\n\nCREATE TABLE HydroPlant_vector_gaugingstations(\n    id INTEGER,\n    vector_index INTEGER NOT NULL,\n    conversion_factor REAL NOT NULL,\n    gaugingstation_id INTEGER,\n    FOREIGN KEY (gaugingstation_id) REFERENCES GaugingStation(id) ON UPDATE CASCADE ON DELETE CASCADE,\n    PRIMARY KEY (id, vector_index)\n) STRICT;","category":"section"},{"location":"psrdatabase/rules/#Set-Attributes","page":"PSRDatabase","title":"Set Attributes","text":"A set is a collection of unique values associated with an element from a Collection. Sets are similar to vectors, but they do not have a specific order and have to be unique.\n\nIn case of a set attribute, a table should be created with its name indicating the name of the Collection and the name of a group of the attribute, separated by _set_, such as COLLECTION_set_GROUP_OF_ATTRIBUTES.\nThe table must contain a Column named id.\nThe table must not have any primary keys.\nThe table must have an unique constraint on the combination of all columns.\n\nExample:\n\nCREATE TABLE HydroPlant_set_gaugingstations(\n    id INTEGER,\n    conversion_factor REAL NOT NULL,\n    gaugingstation_id INTEGER,\n    FOREIGN KEY (gaugingstation_id) REFERENCES GaugingStation(id) ON UPDATE CASCADE ON DELETE CASCADE,\n    UNIQUE (id, conversion_factor, gaugingstation_id)\n) STRICT;","category":"section"},{"location":"psrdatabase/rules/#Time-Series","page":"PSRDatabase","title":"Time Series","text":"Time Series stored in the database should be stored in a table with the name of the Collection followed by _time_series_ and the name of the attribute group, such a COLLECTION_time_series_GROUP_OF_ATTRIBUTES.\nThe table must contain a Column named id.\nA mandatory column named date_time should be created to store the date of the time series data. The date_time column should be of type TEXT and have the NOT NULL constraint.\n\nExample:\n\nCREATE TABLE Resource_time_series_group1 (\n    id INTEGER, \n    date_time TEXT NOT NULL,\n    some_vector1 REAL,\n    some_vector2 REAL,\n    FOREIGN KEY(id) REFERENCES Resource(id) ON DELETE CASCADE ON UPDATE CASCADE,\n    PRIMARY KEY (id, date_time)\n) STRICT; ","category":"section"},{"location":"psrdatabase/rules/#Time-Series-Files","page":"PSRDatabase","title":"Time Series Files","text":"All Time Series files for the elements from a Collection should be stored in a Table\nThe Table name should be the same as the name of the Collection followed by _time_series_files, e. g. COLLECTION_time_series_files.\nEach Column of the table should be named after the name of the attribute.\nEach Column should store the path to the file containing the time series data.\n\nExample:\n\nCREATE TABLE Plant_time_series_files (\n    generation TEXT,\n    cost TEXT\n) STRICT;","category":"section"},{"location":"psrdatabase/rules/#Migrations","page":"PSRDatabase","title":"Migrations","text":"Migrations are an important part of the PSRDatabase framework. They are used to update the database schema to a new version without the need to delete the database and create a new one from scratch. Migrations are defined by two separate .sql files that are stored in the migrations directory of the model. The first file is the up migration and it is used to update the database schema to a new version. The second file is the down migration and it is used to revert the changes made by the up migration. Migrations are stored in directories in the model and they have a specific naming convention. The name of the migration folder should be the number of the version (e.g. /migrations/1/).\n\ndatabase/migrations\n├── 1\n│   ├── up.sql\n│   └── down.sql\n└── 2\n    ├── up.sql\n    └── down.sql","category":"section"},{"location":"psrdatabase/rules/#Creating-a-migration","page":"PSRDatabase","title":"Creating a migration","text":"It is advised to create new migrations using the functions from PSRDatabase. First you need to make sure that the migrations directory is registered  by the function PSRDatabase.set_migrations_folder and after that you can create a new migration using the function PSRDatabase.create_migration. This function will create a new migration file with the name and version specified by the user. The migration file will contain a template for the migration.","category":"section"},{"location":"psrdatabase/rules/#Running-migrations","page":"PSRDatabase","title":"Running migrations","text":"To run migrations you need to use the function PSRDatabase.apply_migrations!. There are various versions of this function, each one tailored to make something easier for the user.","category":"section"},{"location":"psrdatabase/rules/#Testing-migrations","page":"PSRDatabase","title":"Testing migrations","text":"It is very important to test if the migrations of a certain model are working as expected, so the user can be sure that the database schema is updated correctly. To test migrations you need to use the function PSRDatabase.test_migrations(). It is highly advised that each model has one of these functions in their test suite to make sure that the migrations are working as expected.","category":"section"},{"location":"sqlite_examples/migrations/#Migration-Examples","page":"Migration Examples","title":"Migration Examples","text":"Migrations are a way to manage the evolution of the database schema over time. As mentioned in the documentation for PSRDatabase, migrations are defined by two separate .sql files that are stored in the migrations directory of the model. The first file is the up migration and it is used to update the database schema to a new version. The second file is the down migration and it is used to revert the changes made by the up migration. Migrations are stored in directories in the model and they have a specific naming convention. The name of the migration folder should be the number of the version (e.g. /migrations/1/).\n\nIn this section, we will provide some examples of migrations. First, let us start with the first migration, the one that creates the initial database schema.","category":"section"},{"location":"sqlite_examples/migrations/#Adding-two-tables-to-the-database","page":"Migration Examples","title":"Adding two tables to the database","text":"PRAGMA user_version = 1; -- Set the database version to 1\nPRAGMA foreign_keys = ON; -- Enable foreign keys to enforce referential integrity\n\n-- Create the Configuration table\nCREATE TABLE Configuration (\n    id INTEGER PRIMARY KEY,\n    label TEXT UNIQUE NOT NULL,\n    value TEXT NOT NULL\n) ;\n\n-- Create Plant table\nCREATE TABLE Plant (\n    id INTEGER PRIMARY KEY,\n    label TEXT UNIQUE NOT NULL,\n    capacity REAL NOT NULL,\n    bus_name TEXT NOT NULL\n) ;\n\nThis schema is the up.sql migration for version 1. It creates two tables, Configuration and Plant. Now we have to create the down.sql migration for version 1. This migration should drop the tables created in the up.sql migration.\n\nPRAGMA user_version = 0; -- Set the database version to 0\n-- Drop the Configuration table\nDROP TABLE Configuration;\n-- Drop the Plant table\nDROP TABLE Plant;","category":"section"},{"location":"sqlite_examples/migrations/#Adding-a-new-column","page":"Migration Examples","title":"Adding a new column","text":"Now let us create a migration that adds a new column to the Configuration and Plant tables.\n\nPRAGMA user_version = 2; -- Set the database version to 2\nPRAGMA foreign_keys = ON; -- Enable foreign keys to enforce referential integrity\n\n-- Add the description column to the Configuration table\nALTER TABLE Configuration ADD COLUMN description TEXT;\n\n-- Add the type column to the Plant table\nALTER TABLE Plant ADD COLUMN type INTEGER NOT NULL DEFAULT 0;\n\nThis is the up.sql migration for version 2. The down.sql migration should remove the column added in the up.sql migration.\n\nPRAGMA user_version = 1; -- Set the database version to 1\n\n-- Remove the description column from the Configuration table\nALTER TABLE Configuration DROP COLUMN description;\n\n-- Remove the type column from the Plant table\nALTER TABLE Plant DROP COLUMN type;","category":"section"},{"location":"sqlite_examples/migrations/#Renaming-a-table","page":"Migration Examples","title":"Renaming a table","text":"Let us create a migration that renames the Plant table to PowerPlant.\n\nPRAGMA user_version = 3; -- Set the database version to 3\nPRAGMA foreign_keys = ON; -- Enable foreign keys to enforce referential integrity\n\n-- Rename the Plant table to PowerPlant\nALTER TABLE Plant RENAME TO PowerPlant;\n\nThis is the up.sql migration for version 3. The down.sql migration should rename the PowerPlant table back to Plant.\n\nPRAGMA user_version = 2; -- Set the database version to 2\n\n-- Rename the PowerPlant table to Plant\nALTER TABLE PowerPlant RENAME TO Plant;","category":"section"},{"location":"sqlite_examples/migrations/#Adding-a-foreign-key-constraint","page":"Migration Examples","title":"Adding a foreign key constraint","text":"Let us create a migration that adds a foreign key constraint to the PowerPlant table. First, we need to create a new table, Resource, that will be referenced by the PowerPlant table.\n\nAdding a foreign key constraint, however, is not as trivial as adding a column or renaming a table. We need to follow these steps:\n\nDisable foreign key constraints\nStart a transaction\nCreate an auxiliary new_PowerPlant table with the new column and the foreign key constraint\nCopy the data from the PowerPlant table to the new_PowerPlant table\nDrop the PowerPlant table\nRename the new_PowerPlant table to PowerPlant\nCheck if any foreign key constraints were violatet with PRAGMA foreign_key_check\nCommit the transaction\nEnable foreign key constraints \n\nPRAGMA user_version = 4; -- Set the database version to 4\nPRAGMA foreign_keys = ON; -- Enable foreign keys to enforce referential integrity\n\n-- Create the Resource table\nCREATE TABLE Resource (\n    id INTEGER PRIMARY KEY,\n    label TEXT UNIQUE NOT NULL\n) ;\n\n-- Disable foreign key constraints\nPRAGMA foreign_keys = OFF;\n\n-- Start a transaction\nBEGIN TRANSACTION;\n\n-- Create the new PowerPlant table\nCREATE TABLE new_PowerPlant (\n    id INTEGER PRIMARY KEY,\n    label TEXT UNIQUE NOT NULL,\n    capacity REAL NOT NULL,\n    bus_name TEXT NOT NULL,\n    type INTEGER NOT NULL DEFAULT 0,\n    resource_id INTEGER,\n    FOREIGN KEY (resource_id) REFERENCES Resource(id) ON UPDATE CASCADE ON DELETE CASCADE\n) ;\n\n-- Copy the data from the PowerPlant table to the new PowerPlant table\nINSERT INTO new_PowerPlant (id, label, capacity, bus_name, type)\nSELECT id, label, capacity, bus_name, type FROM PowerPlant;\n\n-- Drop the PowerPlant table\nDROP TABLE PowerPlant;\n\n-- Rename the new PowerPlant table to PowerPlant\nALTER TABLE new_PowerPlant RENAME TO PowerPlant;\n\n-- Check if any foreign key constraints were violated\nPRAGMA foreign_key_check;\n\n-- Commit the transaction\nCOMMIT;\n\n-- Enable foreign key constraints\nPRAGMA foreign_keys = ON;\n\nNow, the down.sql migration should revert the changes made by the up.sql migration.\n\nPRAGMA user_version = 3; -- Set the database version to 3\n\n-- Disable foreign key constraints\nPRAGMA foreign_keys = OFF;\n\n-- Start a transaction\nBEGIN TRANSACTION;\n\n-- Create the new PowerPlant table\nCREATE TABLE new_PowerPlant (\n    id INTEGER PRIMARY KEY,\n    label TEXT UNIQUE NOT NULL,\n    capacity REAL NOT NULL,\n    bus_name TEXT NOT NULL,\n    type INTEGER NOT NULL DEFAULT 0\n) ;\n\n-- Copy the data from the PowerPlant table to the new PowerPlant table\nINSERT INTO new_PowerPlant (id, label, capacity, bus_name, type)\nSELECT id, label, capacity, bus_name, type FROM PowerPlant;\n\n-- Drop the PowerPlant table\nDROP TABLE PowerPlant;\n\n-- Rename the new PowerPlant table to PowerPlant\nALTER TABLE new_PowerPlant RENAME TO PowerPlant;\n\n-- Check if any foreign key constraints were violated\nPRAGMA foreign_key_check;\n\n-- Commit the transaction\nCOMMIT;\n\n-- Enable foreign key constraints\nPRAGMA foreign_keys = ON;\n\n-- Drop the Resource table\nDROP TABLE Resource;","category":"section"},{"location":"sqlite_examples/migrations/#Dividing-a-table-into-two-tables","page":"Migration Examples","title":"Dividing a table into two tables","text":"Let us create a migration that divides the PowerPlant table into two tables, HydroPlant and ThermalPlant.  HydroPlant corresponds to the rows with type = 0 and ThermalPlant corresponds to the rows with type = 1.\n\nPRAGMA user_version = 5; -- Set the database version to 5\n\n\n\nPRAGMA foreign_keys = OFF;\nBEGIN TRANSACTION;\n\n-- Create the HydroPlant table\nCREATE TABLE HydroPlant (\n    id INTEGER PRIMARY KEY,\n    label TEXT UNIQUE NOT NULL,\n    capacity REAL NOT NULL,\n    bus_name TEXT NOT NULL,\n    resource_id INTEGER,\n    FOREIGN KEY (resource_id) REFERENCES Resource(id) ON UPDATE CASCADE ON DELETE CASCADE\n) ;\n\n-- Create the ThermalPlant table\nCREATE TABLE ThermalPlant (\n    id INTEGER PRIMARY KEY,\n    label TEXT UNIQUE NOT NULL,\n    capacity REAL NOT NULL,\n    bus_name TEXT NOT NULL,\n    resource_id INTEGER,\n    FOREIGN KEY (resource_id) REFERENCES Resource(id) ON UPDATE CASCADE ON DELETE CASCADE\n) ;\n\n-- Fill the HydroPlant table\nINSERT INTO HydroPlant (id, label, capacity, bus_name, resource_id)\nSELECT id, label, capacity, bus_name, resource_id FROM PowerPlant WHERE type = 0;\n\n-- Fill the ThermalPlant table\nINSERT INTO ThermalPlant (id, label, capacity, bus_name, resource_id)\nSELECT id, label, capacity, bus_name, resource_id FROM PowerPlant WHERE type = 1;\n\n-- Drop the PowerPlant table\nDROP TABLE PowerPlant;\n\nPRAGMA foreign_key_check;\nCOMMIT;\nPRAGMA foreign_keys = ON;\n\n\nThis is the up.sql migration for version 5. The down.sql migration should revert the changes made by the up.sql migration.\n\nPRAGMA user_version = 4; -- Set the database version to 4\nPRAGMA foreign_keys = ON; -- Enable foreign keys to enforce referential integrity\n\n-- Create the PowerPlant table\nCREATE TABLE PowerPlant (\n    id INTEGER PRIMARY KEY,\n    label TEXT UNIQUE NOT NULL,\n    capacity REAL NOT NULL,\n    type INTEGER NOT NULL DEFAULT 0,\n    bus_name TEXT NOT NULL,\n    resource_id INTEGER,\n    FOREIGN KEY (resource_id) REFERENCES Resource(id) ON UPDATE CASCADE ON DELETE CASCADE\n) ;\n\n-- Fill the PowerPlant table\nINSERT INTO PowerPlant (id, label, capacity, bus_name, type, resource_id)\nSELECT id, label, capacity, bus_name, 0, resource_id FROM HydroPlant;\n\nINSERT INTO PowerPlant (id, label, capacity, bus_name, type, resource_id)\nSELECT id, label, capacity, bus_name, 1, resource_id FROM ThermalPlant;\n\n-- Drop the HydroPlant table\nDROP TABLE HydroPlant;\n\n-- Drop the ThermalPlant table\nDROP TABLE ThermalPlant;","category":"section"},{"location":"sqlite_examples/migrations/#Create-a-table-with-data-from-another-table","page":"Migration Examples","title":"Create a table with data from another table","text":"Let us create a migration that adds a new Table Bus with data from the HydroPlant and ThermalPlant tables. These tables already have a column bus_name that will be used to fill the Bus table. After creating the Bus table, we will remove the bus_name column from the HydroPlant and ThermalPlant tables. Moreover, the bus_name column in the PowerPlant table will be replaced by a bus_id column that references the Bus table.\n\nPRAGMA user_version = 6; -- Set the database version to 6\nPRAGMA foreign_keys = ON; -- Enable foreign keys to enforce referential integrity\n\n-- Create the Bus table\nCREATE TABLE Bus (\n    id INTEGER PRIMARY KEY,\n    label TEXT UNIQUE NOT NULL\n) ;\n\n-- Fill the Bus table\nINSERT INTO Bus (label)\nSELECT DISTINCT bus_name FROM HydroPlant;\n\nINSERT INTO Bus (label)\nSELECT DISTINCT bus_name FROM ThermalPlant;\n\nPRAGMA foreign_keys = OFF;\nBEGIN TRANSACTION;\n\n-- Add foreign key \nCREATE TABLE new_HydroPlant (\n    id INTEGER PRIMARY KEY,\n    label TEXT UNIQUE NOT NULL,\n    capacity REAL NOT NULL,\n    resource_id INTEGER,\n    bus_id INTEGER,\n    FOREIGN KEY (resource_id) REFERENCES Resource(id) ON UPDATE CASCADE ON DELETE CASCADE,\n    FOREIGN KEY (bus_id) REFERENCES Bus(id) ON UPDATE CASCADE ON DELETE CASCADE\n) ;\n\nCREATE TABLE new_ThermalPlant (\n    id INTEGER PRIMARY KEY,\n    label TEXT UNIQUE NOT NULL,\n    capacity REAL NOT NULL,\n    resource_id INTEGER,\n    bus_id INTEGER,\n    FOREIGN KEY (resource_id) REFERENCES Resource(id) ON UPDATE CASCADE ON DELETE CASCADE,\n    FOREIGN KEY (bus_id) REFERENCES Bus(id) ON UPDATE CASCADE ON DELETE CASCADE\n) ;\n\n-- Copy the data from the HydroPlant table to the new HydroPlant table\nINSERT INTO new_HydroPlant (id, label, capacity, resource_id)\nSELECT id, label, capacity, resource_id FROM HydroPlant;\n\n-- Copy the data from the ThermalPlant table to the new ThermalPlant table\nINSERT INTO new_ThermalPlant (id, label, capacity, resource_id)\nSELECT id, label, capacity, resource_id FROM ThermalPlant;\n\n-- Add data for the bus_id column\nUPDATE new_HydroPlant SET bus_id = (SELECT Bus.id FROM Bus\nINNER JOIN HydroPlant ON Bus.label = HydroPlant.bus_name AND \nHydroPlant.id = new_HydroPlant.id\n);\nUPDATE new_ThermalPlant SET bus_id = (SELECT Bus.id FROM Bus\nINNER JOIN ThermalPlant ON Bus.label = ThermalPlant.bus_name AND\nThermalPlant.id = new_ThermalPlant.id\n);\n\n-- Drop tables\nDROP TABLE HydroPlant;\nDROP TABLE ThermalPlant;\n\n-- Rename tables\nALTER TABLE new_HydroPlant RENAME TO HydroPlant;\nALTER TABLE new_ThermalPlant RENAME TO ThermalPlant;\n\nPRAGMA foreign_key_check;\nCOMMIT;\nPRAGMA foreign_keys = ON;\n\nThis is the up.sql migration for version 6. The down.sql migration should revert the changes made by the up.sql migration.\n\nPRAGMA user_version = 5; -- Set the database version to 5\n\n\nPRAGMA foreign_keys = OFF;\nBEGIN TRANSACTION;\n\n-- Create auxiliary tables\nCREATE TABLE new_HydroPlant (\n    id INTEGER PRIMARY KEY,\n    label TEXT UNIQUE NOT NULL,\n    capacity REAL NOT NULL,\n    resource_id INTEGER,\n    bus_name TEXT,\n    FOREIGN KEY (resource_id) REFERENCES Resource(id) ON UPDATE CASCADE ON DELETE CASCADE\n) ;\n\nCREATE TABLE new_ThermalPlant (\n    id INTEGER PRIMARY KEY,\n    label TEXT UNIQUE NOT NULL,\n    capacity REAL NOT NULL,\n    resource_id INTEGER,\n    bus_name TEXT,\n    FOREIGN KEY (resource_id) REFERENCES Resource(id) ON UPDATE CASCADE ON DELETE CASCADE\n) ;\n\n-- Copy the data from the HydroPlant table to the new HydroPlant table\nINSERT INTO new_HydroPlant (id, label, capacity, resource_id)\nSELECT id, label, capacity, resource_id FROM HydroPlant;\n\n-- Copy the data from the ThermalPlant table to the new ThermalPlant table\nINSERT INTO new_ThermalPlant (id, label, capacity, resource_id)\nSELECT id, label, capacity, resource_id FROM ThermalPlant;\n\n-- Add data for the bus_name column\nUPDATE new_HydroPlant SET bus_name = (SELECT Bus.label FROM Bus\nINNER JOIN HydroPlant ON Bus.id = HydroPlant.bus_id AND \nHydroPlant.id = new_HydroPlant.id\n);\n\nUPDATE new_ThermalPlant SET bus_name = (SELECT Bus.label FROM Bus\nINNER JOIN ThermalPlant ON Bus.id = ThermalPlant.bus_id AND\nThermalPlant.id = new_ThermalPlant.id\n);\n\n-- Drop tables\nDROP TABLE HydroPlant;\nDROP TABLE ThermalPlant;\n\n-- Rename tables\nALTER TABLE new_HydroPlant RENAME TO HydroPlant;\nALTER TABLE new_ThermalPlant RENAME TO ThermalPlant;\n\n-- Drop the Bus table\nDROP TABLE Bus;\n\nPRAGMA foreign_key_check;\nCOMMIT;\nPRAGMA foreign_keys = ON;","category":"section"},{"location":"psrdatabase/introduction/#SQLite-101","page":"SQLite 101","title":"SQLite 101","text":"SQLite is a software library that provides a relational database management system. The lite in SQLite means light weight in terms of setup, database administration, and required resource. SQLite does NOT require a server to run.\n\nTo learn the basics, we recommend the following resources:\n\nSQLite Tutorial\nSQLite Documentation\n\ntip: Tip\nWe recommend using SQLiteStudio to debug and visualize your SQLite database. You can download it here.","category":"section"},{"location":"#PSRDatabase-Documentation","page":"Home","title":"PSRDatabase Documentation","text":"PSRDatabase is a Julia package that provides an interface to read and write open-source formats for PSR models that use an SQLite database.","category":"section"},{"location":"#Installation","page":"Home","title":"Installation","text":"This package is registered so you can simply add it using Julia's Pkg manager:\n\njulia> import Pkg\n\njulia> Pkg.add(\"PSRDatabase\")","category":"section"},{"location":"#Contributing","page":"Home","title":"Contributing","text":"Users are encouraged to contributing by opening issues and opening pull requests. If you wish to implement a feature please follow  the JuMP Style Guide","category":"section"}]
}
